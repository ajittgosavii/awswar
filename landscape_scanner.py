"""
AWS Landscape Scanner Module - PRODUCTION VERSION 2.1
Comprehensive AWS resource scanning and WAF assessment

Features:
- 40+ AWS service scanning (Production-ready)
- 60+ automated checks across all 6 WAF pillars  
- 65-70% comprehensive WAF coverage
- Automatic WAF pillar mapping
- Detailed findings with remediation steps
- Compliance framework mapping (PCI-DSS, HIPAA, SOC2, CIS AWS, GDPR, ISO27001)
- Cost savings estimates
- Demo mode with realistic data
- PDF report generation support
- PERFORMANCE: Caching for scan results (5 minute TTL)
"""

import streamlit as st
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Any, Callable
from dataclasses import dataclass, field
import json
from functools import wraps

# ============================================================================
# CACHING UTILITIES FOR SCAN PERFORMANCE
# ============================================================================

def cache_scan_result(ttl_seconds: int = 300, cache_key_prefix: str = ""):
    """
    Decorator to cache scan results in session state with TTL.
    Dramatically improves performance by avoiding repeated API calls.
    
    Args:
        ttl_seconds: Time-to-live for cached results (default 5 minutes)
        cache_key_prefix: Optional prefix for cache key
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            # Generate cache key
            # Skip 'self' argument for methods
            cache_args = args[1:] if args and hasattr(args[0], '__class__') else args
            key_parts = [cache_key_prefix or "scan", func.__name__, str(cache_args)[:50]]
            cache_key = "_".join(key_parts).replace(" ", "_")
            
            # Check if cached and not expired
            if cache_key in st.session_state:
                cached = st.session_state[cache_key]
                if isinstance(cached, dict) and 'timestamp' in cached:
                    age = (datetime.now() - cached['timestamp']).total_seconds()
                    if age < ttl_seconds:
                        return cached['data']
            
            # Execute function
            result = func(*args, **kwargs)
            
            # Cache result
            st.session_state[cache_key] = {
                'data': result,
                'timestamp': datetime.now()
            }
            
            return result
        return wrapper
    return decorator

# ============================================================================
# DATA CLASSES
# ============================================================================

@dataclass
class Finding:
    """Represents a WAF-related finding"""
    id: str
    title: str
    description: str
    severity: str  # CRITICAL, HIGH, MEDIUM, LOW, INFO
    pillar: str
    source_service: str
    affected_resources: List[str] = field(default_factory=list)
    recommendation: str = ""
    remediation_steps: List[str] = field(default_factory=list)
    account_id: str = ""
    region: str = ""
    estimated_savings: float = 0.0
    effort: str = "Medium"
    aws_doc_link: str = ""
    compliance_frameworks: List[str] = field(default_factory=list)

@dataclass
class ResourceInventory:
    """AWS Resource inventory summary - ENHANCED FOR PRODUCTION"""
    # Compute
    ec2_instances: int = 0
    ec2_running: int = 0
    ec2_stopped: int = 0
    lambda_functions: int = 0
    ecs_clusters: int = 0
    ecs_services: int = 0
    eks_clusters: int = 0
    eks_nodes: int = 0
    autoscaling_groups: int = 0
    
    # Database
    rds_instances: int = 0
    rds_multi_az: int = 0
    rds_encrypted: int = 0
    rds_backup_enabled: int = 0
    dynamodb_tables: int = 0
    dynamodb_on_demand: int = 0
    elasticache_clusters: int = 0
    
    # Storage
    s3_buckets: int = 0
    s3_public: int = 0
    s3_unencrypted: int = 0
    s3_versioning_enabled: int = 0
    ebs_volumes: int = 0
    ebs_unattached: int = 0
    ebs_unencrypted: int = 0
    ebs_snapshots: int = 0
    efs_filesystems: int = 0
    
    # Networking
    vpcs: int = 0
    subnets: int = 0
    security_groups: int = 0
    security_groups_open: int = 0
    nacls: int = 0
    elastic_ips: int = 0
    elastic_ips_unattached: int = 0
    load_balancers: int = 0
    load_balancers_classic: int = 0
    nat_gateways: int = 0
    vpc_endpoints: int = 0
    transit_gateways: int = 0
    cloudfront_distributions: int = 0
    route53_zones: int = 0
    
    # Security & Compliance
    iam_users: int = 0
    iam_users_no_mfa: int = 0
    iam_users_console_access: int = 0
    iam_roles: int = 0
    iam_policies: int = 0
    kms_keys: int = 0
    kms_keys_no_rotation: int = 0
    secrets_manager_secrets: int = 0
    guardduty_enabled: bool = False
    securityhub_enabled: bool = False
    config_enabled: bool = False
    cloudtrail_multiregion: bool = False
    waf_webacls: int = 0
    shield_advanced: bool = False
    
    # Monitoring & Ops
    cloudwatch_alarms: int = 0
    cloudwatch_log_groups: int = 0
    sns_topics: int = 0
    sqs_queues: int = 0
    eventbridge_rules: int = 0
    systems_manager_compliant: int = 0
    systems_manager_noncompliant: int = 0
    
    # Backup & DR
    backup_vaults: int = 0
    backup_plans: int = 0
    
    # Cost metrics
    reserved_instances: int = 0
    savings_plans: int = 0
    
    # AI/ML Services (NEW)
    sagemaker_notebooks: int = 0
    sagemaker_endpoints: int = 0
    sagemaker_models: int = 0
    sagemaker_pipelines: int = 0
    bedrock_models: int = 0
    bedrock_agents: int = 0
    bedrock_knowledge_bases: int = 0
    bedrock_guardrails: int = 0
    rekognition_projects: int = 0
    comprehend_endpoints: int = 0
    lex_bots: int = 0
    kendra_indexes: int = 0
    ai_ml_services_detected: List[str] = field(default_factory=list)
    has_ai_ml_workloads: bool = False

@dataclass
class PillarScore:
    """Score for a WAF pillar"""
    name: str
    score: int
    findings_count: int
    critical_count: int
    high_count: int
    medium_count: int
    low_count: int
    top_findings: List[Finding] = field(default_factory=list)

@dataclass
class LandscapeAssessment:
    """Complete AWS Landscape Assessment"""
    assessment_id: str
    timestamp: datetime
    accounts_scanned: List[str] = field(default_factory=list)
    regions_scanned: List[str] = field(default_factory=list)
    overall_score: int = 0
    overall_risk: str = "Unknown"
    inventory: ResourceInventory = field(default_factory=ResourceInventory)
    monthly_cost: float = 0.0
    savings_opportunities: float = 0.0
    pillar_scores: Dict[str, PillarScore] = field(default_factory=dict)
    findings: List[Finding] = field(default_factory=list)
    services_scanned: Dict[str, bool] = field(default_factory=dict)
    scan_errors: Dict[str, str] = field(default_factory=dict)
    scan_duration_seconds: float = 0.0
    # AI/ML Assessment (NEW)
    aiml_health_score: int = 0
    aiml_findings: List[Finding] = field(default_factory=list)

# ============================================================================
# DEMO DATA GENERATOR
# ============================================================================

def generate_demo_assessment() -> LandscapeAssessment:
    """Generate comprehensive realistic demo data"""
    
    findings = [
        # CRITICAL Findings
        Finding(
            id="SEC-001",
            title="Root Account Has No MFA Enabled",
            description="The AWS root account does not have Multi-Factor Authentication (MFA) enabled. This is a critical security risk as root account has unrestricted access to all resources.",
            severity="CRITICAL",
            pillar="Security",
            source_service="IAM",
            affected_resources=["Root Account"],
            recommendation="Enable MFA for the root account immediately using a hardware MFA device",
            remediation_steps=[
                "Sign in to AWS Console as root user",
                "Navigate to IAM Dashboard",
                "Click 'Activate MFA on your root account'",
                "Choose 'Virtual MFA device' or 'Hardware MFA device'",
                "Complete the MFA registration process",
                "Store backup codes securely"
            ],
            effort="Low",
            aws_doc_link="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html#id_root-user_manage_mfa",
            compliance_frameworks=["CIS AWS 1.5", "SOC 2", "PCI DSS", "HIPAA"]
        ),
        Finding(
            id="SEC-002",
            title="S3 Bucket with Public Access",
            description="S3 bucket 'company-data-backup' has public access enabled through bucket ACL. This exposes sensitive data to the internet.",
            severity="CRITICAL",
            pillar="Security",
            source_service="S3",
            affected_resources=["company-data-backup", "legacy-uploads"],
            recommendation="Remove public access and enable S3 Block Public Access at account level",
            remediation_steps=[
                "Navigate to S3 console",
                "Select the affected bucket",
                "Go to 'Permissions' tab",
                "Edit 'Block public access' settings",
                "Enable all four block public access options",
                "Review and update bucket policy",
                "Enable S3 Block Public Access at account level"
            ],
            effort="Low",
            aws_doc_link="https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html",
            compliance_frameworks=["CIS AWS 2.1.5", "SOC 2", "GDPR"]
        ),
        Finding(
            id="SEC-003",
            title="IAM Users with Programmatic Access and No Recent Activity",
            description="5 IAM users have programmatic access keys that haven't been used in over 90 days. These dormant credentials pose a security risk.",
            severity="HIGH",
            pillar="Security",
            source_service="IAM",
            affected_resources=["user-legacy-api", "user-jenkins-old", "user-terraform-v1", "user-monitoring", "user-backup-script"],
            recommendation="Rotate or deactivate unused access keys and implement key rotation policy",
            remediation_steps=[
                "Generate IAM Credential Report",
                "Identify keys not used in 90+ days",
                "Contact key owners to verify if still needed",
                "Deactivate unused keys (don't delete immediately)",
                "After 30 days, delete deactivated keys",
                "Implement automated key rotation using AWS Secrets Manager"
            ],
            effort="Medium",
            compliance_frameworks=["CIS AWS 1.12", "SOC 2"]
        ),
        Finding(
            id="SEC-004",
            title="Security Groups Allow Unrestricted SSH Access",
            description="3 security groups allow inbound SSH (port 22) from 0.0.0.0/0, exposing instances to brute force attacks.",
            severity="HIGH",
            pillar="Security",
            source_service="VPC",
            affected_resources=["sg-0abc123-webservers", "sg-0def456-bastion", "sg-0ghi789-legacy"],
            recommendation="Restrict SSH access to specific IP ranges or use AWS Systems Manager Session Manager",
            remediation_steps=[
                "Identify all security groups with 0.0.0.0/0 SSH rules",
                "Document legitimate source IPs that need SSH access",
                "Update rules to allow only specific IP ranges",
                "Consider implementing AWS Systems Manager Session Manager",
                "Enable VPC Flow Logs to monitor access patterns",
                "Set up AWS Config rule to prevent future violations"
            ],
            effort="Medium",
            aws_doc_link="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-rules.html",
            compliance_frameworks=["CIS AWS 5.2", "PCI DSS"]
        ),
        
        # HIGH Findings
        Finding(
            id="REL-001",
            title="RDS Instances Without Multi-AZ",
            description="Production RDS instances are running without Multi-AZ deployment, creating a single point of failure.",
            severity="HIGH",
            pillar="Reliability",
            source_service="RDS",
            affected_resources=["prod-mysql-main", "prod-postgres-analytics"],
            recommendation="Enable Multi-AZ for all production databases",
            remediation_steps=[
                "Identify production RDS instances without Multi-AZ",
                "Schedule maintenance window for conversion",
                "Modify RDS instance to enable Multi-AZ",
                "Monitor replication lag during conversion",
                "Update monitoring alerts for Multi-AZ metrics",
                "Test failover procedure"
            ],
            effort="Medium",
            estimated_savings=0,
            compliance_frameworks=["SOC 2"]
        ),
        Finding(
            id="REL-002",
            title="No Automated Backups for Critical Resources",
            description="12 EC2 instances and 3 RDS databases are not covered by AWS Backup plans.",
            severity="HIGH",
            pillar="Reliability",
            source_service="AWS Backup",
            affected_resources=["i-0abc123-prod-web1", "i-0def456-prod-web2", "prod-mysql-main"],
            recommendation="Create comprehensive AWS Backup plan with appropriate retention",
            remediation_steps=[
                "Inventory all critical resources",
                "Define backup requirements (RPO/RTO)",
                "Create AWS Backup vault with encryption",
                "Create backup plan with appropriate schedule",
                "Assign resources to backup plan using tags",
                "Configure cross-region backup for DR",
                "Test backup restoration quarterly"
            ],
            effort="Medium"
        ),
        Finding(
            id="REL-003",
            title="Single AZ Deployment for Production Workloads",
            description="Production Auto Scaling Group is configured to use only one Availability Zone.",
            severity="HIGH",
            pillar="Reliability",
            source_service="EC2 Auto Scaling",
            affected_resources=["asg-prod-web-servers"],
            recommendation="Configure ASG to span multiple Availability Zones",
            remediation_steps=[
                "Review current ASG configuration",
                "Identify additional subnets in other AZs",
                "Update ASG to include multiple AZ subnets",
                "Verify instance distribution across AZs",
                "Update load balancer health checks"
            ],
            effort="Low"
        ),
        
        # MEDIUM Findings
        Finding(
            id="SEC-005",
            title="CloudTrail Not Enabled for All Regions",
            description="CloudTrail is only configured for us-east-1, missing audit logs from other regions.",
            severity="MEDIUM",
            pillar="Security",
            source_service="CloudTrail",
            affected_resources=["main-trail"],
            recommendation="Enable multi-region CloudTrail with S3 log file validation",
            remediation_steps=[
                "Navigate to CloudTrail console",
                "Edit existing trail or create new one",
                "Enable 'Apply trail to all regions'",
                "Enable log file validation",
                "Configure CloudWatch Logs integration",
                "Set up metric filters for security events"
            ],
            effort="Low",
            compliance_frameworks=["CIS AWS 3.1", "SOC 2", "PCI DSS"]
        ),
        Finding(
            id="SEC-006",
            title="EBS Volumes Without Encryption",
            description="18 EBS volumes are not encrypted at rest, potentially exposing sensitive data.",
            severity="MEDIUM",
            pillar="Security",
            source_service="EC2",
            affected_resources=["vol-0abc123", "vol-0def456", "vol-0ghi789"],
            recommendation="Enable default EBS encryption and migrate existing volumes",
            remediation_steps=[
                "Enable default EBS encryption at account level",
                "Identify all unencrypted volumes",
                "For each volume: create encrypted snapshot",
                "Create new encrypted volume from snapshot",
                "Stop instance, detach old volume, attach new",
                "Verify data integrity and delete old volume"
            ],
            effort="High",
            compliance_frameworks=["CIS AWS 2.2.1", "HIPAA", "PCI DSS"]
        ),
        Finding(
            id="PERF-001",
            title="EC2 Instances Using Previous Generation Types",
            description="12 EC2 instances are using previous generation instance types (m4, c4, r4), missing performance improvements and cost savings.",
            severity="MEDIUM",
            pillar="Performance Efficiency",
            source_service="EC2",
            affected_resources=["i-0abc-m4.xlarge", "i-0def-c4.2xlarge", "i-0ghi-r4.large"],
            recommendation="Migrate to current generation instances (m6i, c6i, r6i) or Graviton",
            remediation_steps=[
                "Analyze current instance utilization with Compute Optimizer",
                "Identify workloads suitable for Graviton (ARM)",
                "Test application compatibility on new instance types",
                "Plan migration during maintenance window",
                "Use EC2 Instance Refresh for ASG migrations",
                "Monitor performance post-migration"
            ],
            effort="Medium",
            estimated_savings=450.0
        ),
        Finding(
            id="COST-001",
            title="Unattached EBS Volumes",
            description="8 EBS volumes are not attached to any instance, incurring unnecessary costs.",
            severity="MEDIUM",
            pillar="Cost Optimization",
            source_service="EC2",
            affected_resources=["vol-0111", "vol-0222", "vol-0333", "vol-0444", "vol-0555"],
            recommendation="Delete unneeded volumes or attach to instances",
            remediation_steps=[
                "List all unattached volumes",
                "Check volume tags for ownership",
                "Create snapshots of volumes with data",
                "Contact owners to verify if needed",
                "Delete confirmed unused volumes",
                "Set up AWS Config rule to alert on unattached volumes"
            ],
            effort="Low",
            estimated_savings=180.0
        ),
        Finding(
            id="COST-002",
            title="Reserved Instance Coverage Below Target",
            description="RI coverage is only 45% for steady-state EC2 workloads. Potential for significant savings.",
            severity="MEDIUM",
            pillar="Cost Optimization",
            source_service="Cost Explorer",
            affected_resources=["EC2 Fleet"],
            recommendation="Purchase Reserved Instances or Savings Plans for steady-state workloads",
            remediation_steps=[
                "Analyze EC2 usage patterns in Cost Explorer",
                "Identify steady-state vs variable workloads",
                "Calculate optimal RI/Savings Plan mix",
                "Consider Compute Savings Plans for flexibility",
                "Start with 1-year No Upfront for lower risk",
                "Review coverage monthly and adjust"
            ],
            effort="Low",
            estimated_savings=2800.0
        ),
        Finding(
            id="COST-003",
            title="Idle Load Balancers",
            description="3 Application Load Balancers have zero healthy targets and no traffic.",
            severity="LOW",
            pillar="Cost Optimization",
            source_service="ELB",
            affected_resources=["alb-staging-old", "alb-test-deprecated", "alb-feature-x"],
            recommendation="Delete unused load balancers",
            remediation_steps=[
                "Verify ALBs have no active traffic",
                "Check if ALBs are referenced in any DNS records",
                "Document and delete unused ALBs",
                "Remove associated target groups"
            ],
            effort="Low",
            estimated_savings=65.0
        ),
        
        # OPERATIONAL EXCELLENCE
        Finding(
            id="OPS-001",
            title="Resources Missing Required Tags",
            description="67 resources are missing required tags (Environment, Owner, CostCenter), hindering governance and cost allocation.",
            severity="MEDIUM",
            pillar="Operational Excellence",
            source_service="Resource Groups",
            affected_resources=["Multiple EC2, RDS, S3 resources"],
            recommendation="Implement and enforce tagging policy using AWS Organizations SCPs",
            remediation_steps=[
                "Define mandatory tag keys and allowed values",
                "Create AWS Config rule for tag compliance",
                "Implement SCP to require tags on resource creation",
                "Use Tag Editor to bulk-apply missing tags",
                "Set up Cost Allocation Tags for billing",
                "Create automation to tag resources on creation"
            ],
            effort="Medium"
        ),
        Finding(
            id="OPS-002",
            title="No Runbooks for Incident Response",
            description="Critical systems lack documented runbooks in AWS Systems Manager.",
            severity="MEDIUM",
            pillar="Operational Excellence",
            source_service="Systems Manager",
            affected_resources=["Production workloads"],
            recommendation="Create SSM Automation runbooks for common operational tasks",
            remediation_steps=[
                "Identify critical operational procedures",
                "Document steps in SSM Automation documents",
                "Test runbooks in non-production",
                "Train operations team on runbook usage",
                "Integrate runbooks with incident management"
            ],
            effort="High"
        ),
        
        # SUSTAINABILITY
        Finding(
            id="SUS-001",
            title="Over-Provisioned Resources in Non-Production",
            description="Development and staging environments use production-sized instances, wasting resources.",
            severity="LOW",
            pillar="Sustainability",
            source_service="EC2",
            affected_resources=["dev-*", "staging-*"],
            recommendation="Right-size non-production environments and implement scheduling",
            remediation_steps=[
                "Analyze non-prod resource utilization",
                "Define appropriate sizing for dev/staging",
                "Implement Instance Scheduler to stop after hours",
                "Use smaller instance types for non-prod",
                "Consider Spot instances for dev workloads"
            ],
            effort="Medium",
            estimated_savings=320.0
        ),
        Finding(
            id="SUS-002",
            title="No Instance Scheduling for Non-Production",
            description="Development instances run 24/7 but are only used during business hours.",
            severity="LOW",
            pillar="Sustainability",
            source_service="EC2",
            affected_resources=["dev-web-1", "dev-api-1", "dev-db-1"],
            recommendation="Implement AWS Instance Scheduler for automatic start/stop",
            remediation_steps=[
                "Deploy AWS Instance Scheduler solution",
                "Define schedules (e.g., M-F 8am-6pm)",
                "Tag instances with appropriate schedules",
                "Monitor cost savings",
                "Adjust schedules based on usage patterns"
            ],
            effort="Low",
            estimated_savings=180.0
        )
    ]
    
    # Create comprehensive inventory
    inventory = ResourceInventory(
        # Compute
        ec2_instances=147, ec2_running=112, ec2_stopped=35,
        lambda_functions=89, ecs_clusters=12, ecs_services=34,
        eks_clusters=5, eks_nodes=28, autoscaling_groups=18,
        # Database
        rds_instances=23, rds_multi_az=15, rds_encrypted=19, rds_backup_enabled=21,
        dynamodb_tables=45, dynamodb_on_demand=12, elasticache_clusters=8,
        # Storage
        s3_buckets=156, s3_public=3, s3_unencrypted=12, s3_versioning_enabled=89,
        ebs_volumes=234, ebs_unattached=18, ebs_unencrypted=23, ebs_snapshots=456,
        efs_filesystems=7,
        # Networking
        vpcs=8, subnets=48, security_groups=178, security_groups_open=12,
        nacls=16, elastic_ips=23, elastic_ips_unattached=5,
        load_balancers=34, load_balancers_classic=7, nat_gateways=12,
        vpc_endpoints=15, transit_gateways=2, cloudfront_distributions=18,
        route53_zones=23,
        # Security
        iam_users=67, iam_users_no_mfa=12, iam_users_console_access=45,
        iam_roles=234, iam_policies=567, kms_keys=34, kms_keys_no_rotation=8,
        secrets_manager_secrets=45, guardduty_enabled=True, securityhub_enabled=True,
        config_enabled=True, cloudtrail_multiregion=True, waf_webacls=5,
        shield_advanced=False,
        # Monitoring
        cloudwatch_alarms=156, cloudwatch_log_groups=234, sns_topics=45,
        sqs_queues=67, eventbridge_rules=89, systems_manager_compliant=98,
        systems_manager_noncompliant=15,
        # Backup
        backup_vaults=3, backup_plans=8,
        # Cost
        reserved_instances=45, savings_plans=12,
        # AI/ML Services (NEW - Demo data)
        sagemaker_notebooks=4,
        sagemaker_endpoints=6,
        sagemaker_models=12,
        sagemaker_pipelines=3,
        bedrock_models=5,
        bedrock_agents=2,
        bedrock_knowledge_bases=3,
        bedrock_guardrails=1,
        rekognition_projects=2,
        comprehend_endpoints=1,
        lex_bots=2,
        kendra_indexes=1,
        ai_ml_services_detected=['sagemaker', 'bedrock', 'rekognition', 'comprehend', 'lex', 'kendra'],
        has_ai_ml_workloads=True
    )
    
    # Add AI/ML specific demo findings
    aiml_findings = [
        Finding(
            id="AIML-001",
            title="SageMaker Endpoints Without Model Monitor",
            description="4 of 6 SageMaker endpoints do not have Model Monitor configured for drift detection.",
            severity="HIGH",
            pillar="Operational Excellence",
            source_service="SageMaker",
            affected_resources=["prod-recommendation-endpoint", "staging-nlp-endpoint", "prod-vision-endpoint", "prod-fraud-endpoint"],
            recommendation="Enable SageMaker Model Monitor for all production endpoints to detect data drift and model quality issues",
            remediation_steps=[
                "Configure baseline statistics from training data",
                "Enable data quality monitoring schedule",
                "Enable model quality monitoring",
                "Set up CloudWatch alarms for violations",
                "Create runbook for drift remediation"
            ],
            effort="Medium",
            compliance_frameworks=["MLOps Best Practices"]
        ),
        Finding(
            id="AIML-002",
            title="Bedrock Agents With Insufficient Guardrails",
            description="2 Bedrock agents are configured but only 1 guardrail exists. Agents with tool access require content filtering.",
            severity="HIGH",
            pillar="Security",
            source_service="Bedrock",
            affected_resources=["customer-support-agent", "research-assistant-agent"],
            recommendation="Configure Bedrock Guardrails for all agents with comprehensive content filtering",
            remediation_steps=[
                "Navigate to Amazon Bedrock console",
                "Create additional guardrail with denied topics",
                "Configure word filters for sensitive content",
                "Associate guardrails with all agents",
                "Test with adversarial prompts"
            ],
            effort="Medium",
            compliance_frameworks=["Responsible AI", "Content Safety"]
        ),
        Finding(
            id="AIML-003",
            title="SageMaker Training Jobs Not Using Spot Instances",
            description="Recent SageMaker training jobs are using on-demand instances, missing up to 90% cost savings.",
            severity="MEDIUM",
            pillar="Cost Optimization",
            source_service="SageMaker",
            affected_resources=["training-job-20241215-a", "training-job-20241218-b", "training-job-20241220-c"],
            recommendation="Enable Managed Spot Training for fault-tolerant training jobs",
            remediation_steps=[
                "Add checkpointing to training scripts",
                "Configure max wait time and max run time",
                "Enable Managed Spot Training in training job config",
                "Monitor Spot interruption metrics"
            ],
            effort="Low",
            estimated_savings=450.0
        ),
        Finding(
            id="AIML-004",
            title="No Explainability for Production ML Models",
            description="Production ML models do not have SageMaker Clarify configured for feature importance and bias detection.",
            severity="MEDIUM",
            pillar="Security",
            source_service="SageMaker",
            affected_resources=["loan-approval-model", "fraud-detection-model", "recommendation-model"],
            recommendation="Configure SageMaker Clarify for model explainability and bias detection",
            remediation_steps=[
                "Create Clarify processing job for bias analysis",
                "Configure SHAP baseline for feature importance",
                "Set up monitoring for bias drift",
                "Document model card with explainability info"
            ],
            effort="Medium",
            compliance_frameworks=["Responsible AI", "Model Governance"]
        ),
        Finding(
            id="AIML-005",
            title="Rekognition Usage Requires Responsible AI Review",
            description="2 Rekognition projects detected. Facial analysis requires careful consideration of bias and consent.",
            severity="INFO",
            pillar="Security",
            source_service="Rekognition",
            affected_resources=["face-verification-project", "content-moderation-project"],
            recommendation="Ensure Rekognition usage complies with responsible AI guidelines",
            remediation_steps=[
                "Review use case for facial analysis appropriateness",
                "Document consent mechanisms for data subjects",
                "Test for demographic bias in detection accuracy",
                "Implement human review for high-stakes decisions"
            ],
            effort="Medium",
            compliance_frameworks=["Responsible AI", "GDPR"]
        )
    ]
    
    # Add AI/ML findings to main findings list
    findings.extend(aiml_findings)
    
    # Calculate pillar scores
    pillar_findings = {}
    for pillar in ['Security', 'Reliability', 'Performance Efficiency', 'Cost Optimization', 'Operational Excellence', 'Sustainability']:
        pillar_findings[pillar] = [f for f in findings if f.pillar == pillar]
    
    pillar_scores = {}
    for pillar, pfindings in pillar_findings.items():
        critical = sum(1 for f in pfindings if f.severity == 'CRITICAL')
        high = sum(1 for f in pfindings if f.severity == 'HIGH')
        medium = sum(1 for f in pfindings if f.severity == 'MEDIUM')
        low = sum(1 for f in pfindings if f.severity in ['LOW', 'INFO'])
        
        score = 100 - (critical * 20) - (high * 10) - (medium * 5) - (low * 2)
        score = max(0, min(100, score))
        
        pillar_scores[pillar] = PillarScore(
            name=pillar,
            score=score,
            findings_count=len(pfindings),
            critical_count=critical,
            high_count=high,
            medium_count=medium,
            low_count=low,
            top_findings=sorted(pfindings, key=lambda f: {'CRITICAL': 0, 'HIGH': 1, 'MEDIUM': 2, 'LOW': 3}.get(f.severity, 4))[:5]
        )
    
    # Calculate overall score (weighted)
    weights = {'Security': 1.5, 'Reliability': 1.3, 'Performance Efficiency': 1.0, 
               'Cost Optimization': 1.0, 'Operational Excellence': 0.9, 'Sustainability': 0.8}
    
    weighted_sum = sum(pillar_scores[p].score * weights.get(p, 1.0) for p in pillar_scores)
    total_weight = sum(weights.get(p, 1.0) for p in pillar_scores)
    overall_score = int(weighted_sum / total_weight)
    
    # Determine risk
    if overall_score >= 80:
        risk = "Low"
    elif overall_score >= 60:
        risk = "Medium"
    elif overall_score >= 40:
        risk = "High"
    else:
        risk = "Critical"
    
    return LandscapeAssessment(
        assessment_id=f"demo-scan-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
        timestamp=datetime.now(),
        accounts_scanned=["123456789012", "987654321098"],
        regions_scanned=["us-east-1", "us-west-2", "eu-west-1"],
        overall_score=overall_score,
        overall_risk=risk,
        inventory=inventory,
        monthly_cost=125000.0,
        savings_opportunities=sum(f.estimated_savings for f in findings),
        pillar_scores=pillar_scores,
        findings=findings,
        services_scanned={
            "IAM": True, "S3": True, "EC2": True, "RDS": True, "VPC": True,
            "Lambda": True, "ECS": True, "EKS": True, "DynamoDB": True,
            "CloudWatch": True, "CloudTrail": True, "GuardDuty": True,
            "Security Hub": True, "Config": True, "KMS": True, "ELB": True,
            "Auto Scaling": True, "Route53": True, "CloudFront": True,
            "ElastiCache": True, "Backup": True, "Systems Manager": True,
            "Secrets Manager": True, "WAF": True, "EFS": True, "SNS": True,
            "EventBridge": True, "EBS": True,
            # AI/ML Services (NEW)
            "SageMaker": True, "Bedrock": True, "AI Services": True
        },
        scan_errors={},
        scan_duration_seconds=45.2,
        # AI/ML Assessment (NEW)
        aiml_health_score=72,  # Demo score
        aiml_findings=aiml_findings
    )

# ============================================================================
# AWS SCANNER CLASS
# ============================================================================

class AWSLandscapeScanner:
    """Scan AWS resources for WAF assessment"""
    
    # Class-level client cache for connection pooling
    _client_cache: Dict[str, Any] = {}
    
    def __init__(self, session):
        self.session = session
        self.account_id = None
        self.findings: List[Finding] = []
        self.inventory = ResourceInventory()
        self.scan_status = {}
        self.scan_errors = {}
        
        try:
            sts = self._get_client('sts')
            self.account_id = sts.get_caller_identity()['Account']
        except:
            pass
    
    def _get_client(self, service_name: str, region: str = None):
        """
        Get cached boto3 client for better performance.
        Reuses clients instead of creating new ones for each call.
        """
        cache_key = f"{service_name}_{region or 'default'}"
        
        if cache_key not in AWSLandscapeScanner._client_cache:
            if region:
                AWSLandscapeScanner._client_cache[cache_key] = self.session.client(
                    service_name, region_name=region
                )
            else:
                AWSLandscapeScanner._client_cache[cache_key] = self._get_client(service_name)
        
        return AWSLandscapeScanner._client_cache[cache_key]
    
    @classmethod
    def clear_client_cache(cls):
        """Clear the client cache (call when session changes)"""
        cls._client_cache.clear()
    
    def _scan_iam(self):
        """Enhanced IAM scanning with MFA, console access, and key rotation checks"""
        iam = self._get_client('iam')
        
        users = iam.list_users()['Users']
        self.inventory.iam_users = len(users)
        
        for user in users[:50]:  # Check more users
            username = user['UserName']
            
            try:
                # Check MFA
                mfa = iam.list_mfa_devices(UserName=username)['MFADevices']
                if not mfa:
                    # Check if user has console access
                    try:
                        login_profile = iam.get_login_profile(UserName=username)
                        self.inventory.iam_users_console_access += 1
                        self.inventory.iam_users_no_mfa += 1
                        
                        self.findings.append(Finding(
                            id=f"iam-nomfa-{username}",
                            title=f"IAM User Without MFA: {username}",
                            description=f"User {username} has console access but no MFA enabled",
                            severity='HIGH',
                            pillar='Security',
                            source_service="IAM",
                            affected_resources=[username],
                            recommendation="Enable MFA for all users with console access",
                            remediation_steps=[
                                "Sign in as the user",
                                "Go to Security Credentials",
                                "Activate MFA with virtual or hardware device"
                            ],
                            effort="Low",
                            compliance_frameworks=["CIS AWS", "NIST", "ISO27001", "PCI-DSS"]
                        ))
                    except:
                        pass
                
                # Check for old access keys
                keys = iam.list_access_keys(UserName=username)['AccessKeyMetadata']
                for key in keys:
                    if key['Status'] == 'Active':
                        age = (datetime.now(key['CreateDate'].tzinfo) - key['CreateDate']).days
                        if age > 90:
                            self.findings.append(Finding(
                                id=f"iam-oldkey-{username}-{key['AccessKeyId'][:8]}",
                                title=f"Old IAM Access Key: {username}",
                                description=f"Access key is {age} days old (>90 days)",
                                severity='MEDIUM',
                                pillar='Security',
                                source_service="IAM",
                                affected_resources=[username],
                                recommendation="Rotate access keys every 90 days",
                                effort="Low",
                                compliance_frameworks=["CIS AWS", "PCI-DSS"]
                            ))
            except:
                pass
        
        self.inventory.iam_roles = len(iam.list_roles()['Roles'])
        self.inventory.iam_policies = len(iam.list_policies(Scope='Local')['Policies'])
    
    def _scan_s3(self):
        """Enhanced S3 scanning with encryption, public access, versioning, and logging checks"""
        s3 = self._get_client('s3')
        buckets = s3.list_buckets()['Buckets']
        self.inventory.s3_buckets = len(buckets)
        
        for bucket in buckets[:100]:  # Limit to avoid throttling
            bucket_name = bucket['Name']
            
            try:
                # Check public access
                try:
                    public_block = s3.get_public_access_block(Bucket=bucket_name)
                    config = public_block['PublicAccessBlockConfiguration']
                    if not all([config['BlockPublicAcls'], config['BlockPublicPolicy'], 
                               config['IgnorePublicAcls'], config['RestrictPublicBuckets']]):
                        self.inventory.s3_public += 1
                        
                        self.findings.append(Finding(
                            id=f"s3-public-{bucket_name[:20]}",
                            title=f"S3 Bucket May Have Public Access: {bucket_name}",
                            description=f"Bucket {bucket_name} does not have all public access blocks enabled",
                            severity='CRITICAL',
                            pillar='Security',
                            source_service="S3",
                            affected_resources=[bucket_name],
                            recommendation="Enable Block All Public Access unless specifically required",
                            remediation_steps=[
                                "Go to S3 console",
                                "Select bucket",
                                "Go to Permissions tab",
                                "Edit Block Public Access settings",
                                "Enable all four settings"
                            ],
                            effort="Low",
                            compliance_frameworks=["CIS AWS", "PCI-DSS", "HIPAA", "GDPR"]
                        ))
                except s3.exceptions.NoSuchPublicAccessBlockConfiguration:
                    self.inventory.s3_public += 1
                
                # Check encryption
                try:
                    encryption = s3.get_bucket_encryption(Bucket=bucket_name)
                except s3.exceptions.ServerSideEncryptionConfigurationNotFoundError:
                    self.inventory.s3_unencrypted += 1
                    
                    self.findings.append(Finding(
                        id=f"s3-noenc-{bucket_name[:20]}",
                        title=f"S3 Bucket Without Encryption: {bucket_name}",
                        description=f"Bucket {bucket_name} does not have default encryption enabled",
                        severity='HIGH',
                        pillar='Security',
                        source_service="S3",
                        affected_resources=[bucket_name],
                        recommendation="Enable default encryption with SSE-KMS or SSE-S3",
                        remediation_steps=[
                            "Go to S3 console",
                            "Select bucket",
                            "Go to Properties",
                            "Enable Default Encryption",
                            "Choose SSE-KMS (recommended) or SSE-S3"
                        ],
                        effort="Low",
                        compliance_frameworks=["HIPAA", "PCI-DSS", "GDPR"]
                    ))
                
                # Check versioning
                try:
                    versioning = s3.get_bucket_versioning(Bucket=bucket_name)
                    if versioning.get('Status') == 'Enabled':
                        self.inventory.s3_versioning_enabled += 1
                except:
                    pass
                
            except Exception as e:
                pass
    
    def _scan_ec2(self, region: str):
        """Enhanced EC2 scanning with stopped instances and security group checks"""
        ec2 = self._get_client('ec2', region_name=region)
        
        # Instances
        for reservation in ec2.describe_instances()['Reservations']:
            for instance in reservation['Instances']:
                self.inventory.ec2_instances += 1
                state = instance['State']['Name']
                
                if state == 'running':
                    self.inventory.ec2_running += 1
                elif state == 'stopped':
                    self.inventory.ec2_stopped += 1
        
        # Volumes
        volumes = ec2.describe_volumes()['Volumes']
        for vol in volumes:
            self.inventory.ebs_volumes += 1
            if vol['State'] == 'available':
                self.inventory.ebs_unattached += 1
            if not vol.get('Encrypted'):
                self.inventory.ebs_unencrypted += 1
        
        # VPCs and security groups
        self.inventory.vpcs = len(ec2.describe_vpcs()['Vpcs'])
        
        # Security groups - check for overly permissive rules
        sgs = ec2.describe_security_groups()['SecurityGroups']
        self.inventory.security_groups = len(sgs)
        
        for sg in sgs[:50]:
            for rule in sg.get('IpPermissions', []):
                for ip_range in rule.get('IpRanges', []):
                    if ip_range.get('CidrIp') == '0.0.0.0/0':
                        self.inventory.security_groups_open += 1
                        
                        from_port = rule.get('FromPort', 'all')
                        severity = 'CRITICAL' if from_port in [22, 3389] else 'HIGH'
                        
                        self.findings.append(Finding(
                            id=f"sg-open-{sg['GroupId'][:12]}-{from_port}",
                            title=f"Security Group Open to Internet: {sg['GroupName']}",
                            description=f"Allows inbound traffic on port {from_port} from 0.0.0.0/0",
                            severity=severity,
                            pillar='Security',
                            source_service="EC2",
                            affected_resources=[sg['GroupId']],
                            recommendation="Restrict to specific IP ranges",
                            effort="Medium",
                            compliance_frameworks=["CIS AWS", "PCI-DSS"]
                        ))
                        break
    
    def _scan_rds(self, region: str):
        """Enhanced RDS scanning with encryption, backups, and public access checks"""
        try:
            rds = self._get_client('rds', region_name=region)
            dbs = rds.describe_db_instances()['DBInstances']
            
            for db in dbs:
                self.inventory.rds_instances += 1
                db_id = db['DBInstanceIdentifier']
                
                # Check Multi-AZ
                if db.get('MultiAZ'):
                    self.inventory.rds_multi_az += 1
                else:
                    severity = 'MEDIUM' if db.get('DBInstanceClass', '').startswith('db.t') else 'HIGH'
                    
                    self.findings.append(Finding(
                        id=f"rds-singleaz-{db_id[:20]}",
                        title=f"RDS Instance Not Multi-AZ: {db_id}",
                        description="Database is deployed in single AZ",
                        severity=severity,
                        pillar='Reliability',
                        source_service="RDS",
                        affected_resources=[db_id],
                        recommendation="Enable Multi-AZ for production databases",
                        remediation_steps=[
                            "Plan maintenance window",
                            "Modify RDS instance",
                            "Enable Multi-AZ deployment",
                            "Test failover"
                        ],
                        effort="Low"
                    ))
                
                # Check encryption
                if db.get('StorageEncrypted'):
                    self.inventory.rds_encrypted += 1
                else:
                    self.findings.append(Finding(
                        id=f"rds-noenc-{db_id[:20]}",
                        title=f"RDS Instance Not Encrypted: {db_id}",
                        description="Database storage is not encrypted at rest",
                        severity='CRITICAL',
                        pillar='Security',
                        source_service="RDS",
                        affected_resources=[db_id],
                        recommendation="Create encrypted snapshot and restore",
                        effort="High",
                        compliance_frameworks=["HIPAA", "PCI-DSS", "GDPR"]
                    ))
                
                # Check backups
                if db.get('BackupRetentionPeriod', 0) > 0:
                    self.inventory.rds_backup_enabled += 1
                else:
                    self.findings.append(Finding(
                        id=f"rds-nobackup-{db_id[:20]}",
                        title=f"RDS Without Automated Backups: {db_id}",
                        description="Automated backups are not configured",
                        severity='HIGH',
                        pillar='Reliability',
                        source_service="RDS",
                        affected_resources=[db_id],
                        recommendation="Enable automated backups with 7+ day retention",
                        remediation_steps=[
                            "Modify DB instance",
                            "Set backup retention period to 7-35 days",
                            "Configure backup window",
                            "Verify backups are being created"
                        ],
                        effort="Low",
                        compliance_frameworks=["SOC2", "ISO27001"]
                    ))
                
                # Check public accessibility
                if db.get('PubliclyAccessible'):
                    self.findings.append(Finding(
                        id=f"rds-public-{db_id[:20]}",
                        title=f"RDS Instance Publicly Accessible: {db_id}",
                        description="Database is accessible from the internet",
                        severity='CRITICAL',
                        pillar='Security',
                        source_service="RDS",
                        affected_resources=[db_id],
                        recommendation="Disable public accessibility",
                        effort="Low",
                        compliance_frameworks=["CIS AWS", "PCI-DSS"]
                    ))
        except:
            pass
    
    def _scan_vpc(self, region: str):
        """Scan VPC"""
        ec2 = self._get_client('ec2', region_name=region)
        self.inventory.security_groups = len(ec2.describe_security_groups()['SecurityGroups'])
    
    def _scan_cloudtrail(self, region: str):
        """Enhanced CloudTrail scanning with multi-region and validation checks"""
        try:
            ct = self._get_client('cloudtrail', region_name=region)
            trails = ct.describe_trails()['trailList']
            
            has_multiregion = any(t.get('IsMultiRegionTrail') for t in trails)
            
            if has_multiregion:
                self.inventory.cloudtrail_multiregion = True
            else:
                self.findings.append(Finding(
                    id="ct-no-multiregion",
                    title="CloudTrail Not Multi-Region",
                    description="No multi-region CloudTrail configured for comprehensive logging",
                    severity='HIGH',
                    pillar='Security',
                    source_service="CloudTrail",
                    affected_resources=[region],
                    recommendation="Enable multi-region CloudTrail with log file validation",
                    effort="Low",
                    compliance_frameworks=["CIS AWS", "PCI-DSS", "HIPAA"]
                ))
            
            # Check log file validation
            for trail in trails:
                if not trail.get('LogFileValidationEnabled'):
                    self.findings.append(Finding(
                        id=f"ct-noval-{trail['Name'][:20]}",
                        title=f"CloudTrail Without Log Validation: {trail['Name']}",
                        description="Log file integrity validation is not enabled",
                        severity='MEDIUM',
                        pillar='Security',
                        source_service="CloudTrail",
                        affected_resources=[trail['Name']],
                        recommendation="Enable log file validation",
                        effort="Low"
                    ))
        except:
            pass
    # =============================================================================
# PRODUCTION SCANNER ADDITIONS
# Add these methods to your AWSLandscapeScanner class
# These 20+ new methods will bring your scanner to 65-70% WAF coverage
# =============================================================================

# ADD THESE METHODS TO THE AWSLandscapeScanner CLASS
# Insert after the existing _scan_cloudtrail method

    def _scan_kms(self):
        """Scan KMS keys for rotation"""
        try:
            kms = self._get_client('kms')
            keys = kms.list_keys()['Keys']
            
            for key in keys[:50]:  # Limit to avoid throttling
                key_id = key['KeyId']
                
                try:
                    metadata = kms.describe_key(KeyId=key_id)['KeyMetadata']
                    
                    # Skip AWS managed keys
                    if metadata['KeyManager'] == 'AWS':
                        continue
                    
                    self.inventory.kms_keys += 1
                    
                    # Check key rotation
                    try:
                        rotation = kms.get_key_rotation_status(KeyId=key_id)
                        if not rotation['KeyRotationEnabled']:
                            self.inventory.kms_keys_no_rotation += 1
                            
                            self.findings.append(Finding(
                                id=f"kms-norot-{key_id[:8]}",
                                title=f"KMS Key Without Rotation: {metadata.get('Description', key_id[:16])}",
                                description="Automatic key rotation is not enabled",
                                severity='MEDIUM',
                                pillar='Security',
                                source_service="KMS",
                                affected_resources=[key_id],
                                recommendation="Enable automatic key rotation",
                                remediation_steps=[
                                    "Go to KMS console",
                                    "Select the key",
                                    "Go to Key rotation tab",
                                    "Enable automatic key rotation"
                                ],
                                effort="Low",
                                compliance_frameworks=["PCI-DSS", "HIPAA", "ISO27001"]
                            ))
                    except:
                        pass
                except:
                    pass
        except:
            pass
    
    def _scan_secrets_manager(self):
        """Scan Secrets Manager for rotation"""
        try:
            sm = self._get_client('secretsmanager')
            secrets = sm.list_secrets()['SecretList']
            self.inventory.secrets_manager_secrets = len(secrets)
            
            for secret in secrets[:50]:
                if not secret.get('RotationEnabled'):
                    self.findings.append(Finding(
                        id=f"sm-norot-{secret['Name'][:20]}",
                        title=f"Secret Without Rotation: {secret['Name']}",
                        description="Automatic secret rotation is not enabled",
                        severity='MEDIUM',
                        pillar='Security',
                        source_service="Secrets Manager",
                        affected_resources=[secret['Name']],
                        recommendation="Enable automatic rotation for secrets",
                        effort="Medium",
                        compliance_frameworks=["SOC2", "ISO27001"]
                    ))
        except:
            pass
    
    def _scan_guardduty(self, region: str):
        """Scan GuardDuty for threat detection"""
        try:
            gd = self._get_client('guardduty', region_name=region)
            detectors = gd.list_detectors()['DetectorIds']
            
            if detectors:
                self.inventory.guardduty_enabled = True
                
                # Check for findings
                for detector_id in detectors:
                    try:
                        findings = gd.list_findings(DetectorId=detector_id, MaxResults=50)
                        finding_ids = findings['FindingIds']
                        
                        if finding_ids:
                            details = gd.get_findings(DetectorId=detector_id, FindingIds=finding_ids)
                            
                            for finding in details['Findings']:
                                severity = finding['Severity']
                                if severity >= 7.0:  # High severity
                                    resource_id = finding.get('Resource', {}).get('InstanceDetails', {}).get('InstanceId', 'Unknown')
                                    
                                    self.findings.append(Finding(
                                        id=f"gd-{finding['Id'][:16]}",
                                        title=f"GuardDuty Finding: {finding['Type']}",
                                        description=finding.get('Description', 'High-severity security finding detected'),
                                        severity='HIGH',
                                        pillar='Security',
                                        source_service="GuardDuty",
                                        affected_resources=[resource_id],
                                        recommendation="Investigate and remediate GuardDuty finding immediately",
                                        effort="High",
                                        compliance_frameworks=["CIS AWS", "SOC2"]
                                    ))
                    except:
                        pass
            else:
                self.findings.append(Finding(
                    id="gd-disabled",
                    title="GuardDuty Not Enabled",
                    description="GuardDuty threat detection is not enabled in this region",
                    severity='HIGH',
                    pillar='Security',
                    source_service="GuardDuty",
                    affected_resources=[region],
                    recommendation="Enable GuardDuty for continuous threat detection",
                    effort="Low",
                    compliance_frameworks=["CIS AWS", "PCI-DSS"]
                ))
        except:
            pass
    
    def _scan_securityhub(self, region: str):
        """Scan Security Hub status"""
        try:
            sh = self._get_client('securityhub', region_name=region)
            
            try:
                hub = sh.describe_hub()
                self.inventory.securityhub_enabled = True
            except:
                self.inventory.securityhub_enabled = False
                self.findings.append(Finding(
                    id="sh-disabled",
                    title="Security Hub Not Enabled",
                    description="AWS Security Hub provides centralized security findings",
                    severity='MEDIUM',
                    pillar='Security',
                    source_service="Security Hub",
                    affected_resources=[region],
                    recommendation="Enable Security Hub for consolidated security view",
                    effort="Low",
                    compliance_frameworks=["CIS AWS", "PCI-DSS", "NIST"]
                ))
        except:
            pass
    
    def _scan_config(self, region: str):
        """Scan AWS Config for compliance"""
        try:
            config = self._get_client('config', region_name=region)
            
            try:
                recorders = config.describe_configuration_recorders()
                if recorders['ConfigurationRecorders']:
                    self.inventory.config_enabled = True
                    
                    # Check compliance
                    try:
                        rules = config.describe_compliance_by_config_rule()
                        for rule in rules.get('ComplianceByConfigRules', [])[:20]:
                            if rule['Compliance']['ComplianceType'] == 'NON_COMPLIANT':
                                self.findings.append(Finding(
                                    id=f"config-nc-{rule['ConfigRuleName'][:20]}",
                                    title=f"Config Rule Non-Compliant: {rule['ConfigRuleName']}",
                                    description="Resources do not comply with Config rule",
                                    severity='MEDIUM',
                                    pillar='Security',
                                    source_service="Config",
                                    affected_resources=[rule['ConfigRuleName']],
                                    recommendation="Review and remediate non-compliant resources",
                                    effort="Medium"
                                ))
                    except:
                        pass
                else:
                    self.findings.append(Finding(
                        id="config-disabled",
                        title="AWS Config Not Enabled",
                        description="Config provides resource inventory and compliance monitoring",
                        severity='MEDIUM',
                        pillar='Operational Excellence',
                        source_service="Config",
                        affected_resources=[region],
                        recommendation="Enable AWS Config for compliance monitoring",
                        effort="Low",
                        compliance_frameworks=["CIS AWS", "PCI-DSS"]
                    ))
            except:
                pass
        except:
            pass
    
    def _scan_waf(self, region: str):
        """Scan AWS WAF"""
        try:
            waf = self._get_client('wafv2', region_name=region)
            
            webacls = waf.list_web_acls(Scope='REGIONAL')['WebACLs']
            self.inventory.waf_webacls = len(webacls)
            
            if len(webacls) == 0:
                self.findings.append(Finding(
                    id="waf-none",
                    title="No WAF WebACLs Configured",
                    description="AWS WAF not configured for application protection",
                    severity='MEDIUM',
                    pillar='Security',
                    source_service="WAF",
                    affected_resources=[region],
                    recommendation="Configure AWS WAF for web application protection",
                    effort="Medium",
                    compliance_frameworks=["PCI-DSS", "OWASP"]
                ))
        except:
            pass
    
    def _scan_lambda(self, region: str):
        """Enhanced Lambda scanning"""
        try:
            lmb = self._get_client('lambda', region_name=region)
            
            functions = lmb.list_functions()['Functions']
            self.inventory.lambda_functions = len(functions)
            
            for func in functions[:50]:
                func_name = func['FunctionName']
                
                # Check for DLQ
                if 'DeadLetterConfig' not in func or not func.get('DeadLetterConfig', {}).get('TargetArn'):
                    self.findings.append(Finding(
                        id=f"lambda-nodlq-{func_name[:20]}",
                        title=f"Lambda Without DLQ: {func_name}",
                        description="No Dead Letter Queue configured for failed invocations",
                        severity='MEDIUM',
                        pillar='Reliability',
                        source_service="Lambda",
                        affected_resources=[func_name],
                        recommendation="Configure SQS or SNS Dead Letter Queue",
                        effort="Low"
                    ))
                
                # Check for secrets in environment variables
                if 'Environment' in func:
                    env_vars = func['Environment'].get('Variables', {})
                    for key in env_vars.keys():
                        if any(word in key.lower() for word in ['password', 'secret', 'key', 'token', 'api']):
                            self.findings.append(Finding(
                                id=f"lambda-envsecret-{func_name[:20]}",
                                title=f"Potential Secret in Environment: {func_name}",
                                description=f"Environment variable '{key}' may contain sensitive data",
                                severity='HIGH',
                                pillar='Security',
                                source_service="Lambda",
                                affected_resources=[func_name],
                                recommendation="Use AWS Secrets Manager or Parameter Store",
                                effort="Medium",
                                compliance_frameworks=["SOC2", "ISO27001"]
                            ))
                            break
        except:
            pass
    
    def _scan_dynamodb(self, region: str):
        """Scan DynamoDB tables"""
        try:
            ddb = self._get_client('dynamodb', region_name=region)
            
            tables = ddb.list_tables()['TableNames']
            self.inventory.dynamodb_tables = len(tables)
            
            for table_name in tables[:20]:
                try:
                    table = ddb.describe_table(TableName=table_name)['Table']
                    
                    # Check billing mode
                    if table.get('BillingModeSummary', {}).get('BillingMode') == 'PAY_PER_REQUEST':
                        self.inventory.dynamodb_on_demand += 1
                    
                    # Check backups
                    try:
                        backup_desc = ddb.describe_continuous_backups(TableName=table_name)
                        pitr_status = backup_desc.get('ContinuousBackupsDescription', {}).get('PointInTimeRecoveryDescription', {}).get('PointInTimeRecoveryStatus')
                        
                        if pitr_status != 'ENABLED':
                            self.findings.append(Finding(
                                id=f"ddb-nopitr-{table_name[:20]}",
                                title=f"DynamoDB Table Without PITR: {table_name}",
                                description="Point-in-time recovery is not enabled",
                                severity='MEDIUM',
                                pillar='Reliability',
                                source_service="DynamoDB",
                                affected_resources=[table_name],
                                recommendation="Enable point-in-time recovery",
                                effort="Low"
                            ))
                    except:
                        pass
                except:
                    pass
        except:
            pass
    
    def _scan_elasticache(self, region: str):
        """Scan ElastiCache clusters"""
        try:
            ec = self._get_client('elasticache', region_name=region)
            
            clusters = ec.describe_cache_clusters()['CacheClusters']
            self.inventory.elasticache_clusters = len(clusters)
            
            for cluster in clusters[:20]:
                if not cluster.get('AtRestEncryptionEnabled'):
                    self.findings.append(Finding(
                        id=f"ec-noenc-{cluster['CacheClusterId'][:20]}",
                        title=f"ElastiCache Without Encryption: {cluster['CacheClusterId']}",
                        description="Cache data is not encrypted at rest",
                        severity='HIGH',
                        pillar='Security',
                        source_service="ElastiCache",
                        affected_resources=[cluster['CacheClusterId']],
                        recommendation="Enable encryption at rest for new clusters",
                        effort="High",
                        compliance_frameworks=["HIPAA", "PCI-DSS"]
                    ))
        except:
            pass
    
    def _scan_ecs(self, region: str):
        """Scan ECS clusters"""
        try:
            ecs = self._get_client('ecs', region_name=region)
            
            clusters = ecs.list_clusters()['clusterArns']
            self.inventory.ecs_clusters = len(clusters)
            
            for cluster_arn in clusters:
                services = ecs.list_services(cluster=cluster_arn)['serviceArns']
                self.inventory.ecs_services += len(services)
        except:
            pass
    
    def _scan_eks(self, region: str):
        """Scan EKS clusters"""
        try:
            eks = self._get_client('eks', region_name=region)
            
            clusters = eks.list_clusters()['clusters']
            self.inventory.eks_clusters = len(clusters)
            
            for cluster_name in clusters:
                try:
                    cluster = eks.describe_cluster(name=cluster_name)['cluster']
                    
                    # Check public endpoint
                    if cluster.get('resourcesVpcConfig', {}).get('endpointPublicAccess'):
                        self.findings.append(Finding(
                            id=f"eks-public-{cluster_name[:20]}",
                            title=f"EKS Cluster with Public Endpoint: {cluster_name}",
                            description="Cluster API endpoint is publicly accessible",
                            severity='MEDIUM',
                            pillar='Security',
                            source_service="EKS",
                            affected_resources=[cluster_name],
                            recommendation="Disable public access or use CIDR restrictions",
                            effort="Medium"
                        ))
                    
                    # Check logging
                    logging = cluster.get('logging', {}).get('clusterLogging', [])
                    if not logging or not any(log.get('enabled') for log in logging):
                        self.findings.append(Finding(
                            id=f"eks-nolog-{cluster_name[:20]}",
                            title=f"EKS Cluster Without Logging: {cluster_name}",
                            description="Control plane logging is not enabled",
                            severity='MEDIUM',
                            pillar='Operational Excellence',
                            source_service="EKS",
                            affected_resources=[cluster_name],
                            recommendation="Enable control plane logging",
                            effort="Low"
                        ))
                except:
                    pass
        except:
            pass
    
    def _scan_autoscaling(self, region: str):
        """Scan Auto Scaling Groups"""
        try:
            asg = self._get_client('autoscaling', region_name=region)
            
            groups = asg.describe_auto_scaling_groups()['AutoScalingGroups']
            self.inventory.autoscaling_groups = len(groups)
            
            for group in groups[:20]:
                if group.get('HealthCheckType') == 'EC2':
                    self.findings.append(Finding(
                        id=f"asg-hc-{group['AutoScalingGroupName'][:20]}",
                        title=f"ASG Using EC2 Health Checks: {group['AutoScalingGroupName']}",
                        description="Consider using ELB health checks for better reliability",
                        severity='LOW',
                        pillar='Reliability',
                        source_service="Auto Scaling",
                        affected_resources=[group['AutoScalingGroupName']],
                        recommendation="Enable ELB health checks",
                        effort="Low"
                    ))
        except:
            pass
    
    def _scan_ebs_volumes(self, region: str):
        """Enhanced EBS volume scanning"""
        ec2 = self._get_client('ec2', region_name=region)
        
        try:
            volumes = ec2.describe_volumes()['Volumes']
            
            for vol in volumes:
                self.inventory.ebs_volumes += 1
                vol_id = vol['VolumeId']
                size = vol['Size']
                vol_type = vol['VolumeType']
                
                # Unattached volumes
                if vol['State'] == 'available':
                    self.inventory.ebs_unattached += 1
                    
                    cost_per_gb = 0.10
                    monthly_cost = size * cost_per_gb
                    
                    self.findings.append(Finding(
                        id=f"ebs-unattached-{vol_id[:12]}",
                        title=f"Unattached EBS Volume: {vol_id}",
                        description=f"{size}GB volume not attached to any instance",
                        severity='MEDIUM',
                        pillar='Cost Optimization',
                        source_service="EC2",
                        affected_resources=[vol_id],
                        recommendation="Delete or snapshot unused volumes",
                        effort="Low",
                        estimated_savings=monthly_cost
                    ))
                
                # gp2 to gp3 migration
                if vol_type == 'gp2':
                    savings = size * 0.02
                    
                    self.findings.append(Finding(
                        id=f"ebs-gp2-{vol_id[:12]}",
                        title=f"EBS Volume Using gp2: {vol_id}",
                        description="Upgrade to gp3 for 20% cost savings",
                        severity='LOW',
                        pillar='Performance Efficiency',
                        source_service="EC2",
                        affected_resources=[vol_id],
                        recommendation="Migrate to gp3 volume type",
                        effort="Low",
                        estimated_savings=savings
                    ))
                
                # Unencrypted volumes
                if not vol.get('Encrypted'):
                    self.inventory.ebs_unencrypted += 1
                    
                    self.findings.append(Finding(
                        id=f"ebs-noenc-{vol_id[:12]}",
                        title=f"Unencrypted EBS Volume: {vol_id}",
                        description="EBS volume is not encrypted at rest",
                        severity='HIGH',
                        pillar='Security',
                        source_service="EC2",
                        affected_resources=[vol_id],
                        recommendation="Snapshot and re-create with encryption",
                        effort="Medium",
                        compliance_frameworks=["HIPAA", "PCI-DSS", "GDPR"]
                    ))
            
            # Old snapshots
            snapshots = ec2.describe_snapshots(OwnerIds=['self'])['Snapshots']
            self.inventory.ebs_snapshots = len(snapshots)
            
            old_snapshots = []
            for snap in snapshots:
                age = (datetime.now(snap['StartTime'].tzinfo) - snap['StartTime']).days
                if age > 90:
                    old_snapshots.append(snap['SnapshotId'])
            
            if len(old_snapshots) > 10:
                self.findings.append(Finding(
                    id="ebs-oldsnaps",
                    title=f"{len(old_snapshots)} Old EBS Snapshots",
                    description=f"Snapshots older than 90 days may no longer be needed",
                    severity='MEDIUM',
                    pillar='Cost Optimization',
                    source_service="EC2",
                    affected_resources=old_snapshots[:5],
                    recommendation="Review and delete unnecessary old snapshots",
                    effort="Low",
                    estimated_savings=len(old_snapshots) * 5
                ))
        except:
            pass
    
    def _scan_elastic_ips(self, region: str):
        """Scan for unused Elastic IPs"""
        try:
            ec2 = self._get_client('ec2', region_name=region)
            
            eips = ec2.describe_addresses()['Addresses']
            
            for eip in eips:
                self.inventory.elastic_ips += 1
                
                if 'InstanceId' not in eip:
                    self.inventory.elastic_ips_unattached += 1
                    
                    self.findings.append(Finding(
                        id=f"eip-unattached-{eip['AllocationId'][:12]}",
                        title=f"Unattached Elastic IP: {eip.get('PublicIp', 'N/A')}",
                        description="Elastic IP not associated with a running instance",
                        severity='LOW',
                        pillar='Cost Optimization',
                        source_service="EC2",
                        affected_resources=[eip['AllocationId']],
                        recommendation="Release unused Elastic IPs",
                        effort="Low",
                        estimated_savings=3.65
                    ))
        except:
            pass
    
    def _scan_elb(self, region: str):
        """Enhanced ELB scanning"""
        try:
            # Classic Load Balancers
            elb = self._get_client('elb', region_name=region)
            classic_lbs = elb.describe_load_balancers()['LoadBalancerDescriptions']
            self.inventory.load_balancers_classic = len(classic_lbs)
            
            for lb in classic_lbs:
                lb_name = lb['LoadBalancerName']
                
                if not lb.get('Instances'):
                    self.findings.append(Finding(
                        id=f"elb-idle-{lb_name[:20]}",
                        title=f"Idle Classic Load Balancer: {lb_name}",
                        description="Load balancer has no registered instances",
                        severity='MEDIUM',
                        pillar='Cost Optimization',
                        source_service="ELB",
                        affected_resources=[lb_name],
                        recommendation="Delete unused load balancers",
                        effort="Low",
                        estimated_savings=18
                    ))
            
            # Modern Load Balancers
            elbv2 = self._get_client('elbv2', region_name=region)
            modern_lbs = elbv2.describe_load_balancers()['LoadBalancers']
            self.inventory.load_balancers = len(classic_lbs) + len(modern_lbs)
        except:
            pass
    
    def _scan_cloudwatch(self, region: str):
        """Scan CloudWatch alarms and logs"""
        try:
            cw = self._get_client('cloudwatch', region_name=region)
            logs = self._get_client('logs', region_name=region)
            
            # Alarms
            alarms = cw.describe_alarms()['MetricAlarms']
            self.inventory.cloudwatch_alarms = len(alarms)
            
            # Log Groups
            log_groups = logs.describe_log_groups()['logGroups']
            self.inventory.cloudwatch_log_groups = len(log_groups)
            
            for lg in log_groups[:50]:
                if 'retentionInDays' not in lg:
                    self.findings.append(Finding(
                        id=f"cw-noret-{lg['logGroupName'][:20]}",
                        title=f"CloudWatch Log Without Retention: {lg['logGroupName'][:40]}",
                        description="Log retention is set to 'Never Expire'",
                        severity='LOW',
                        pillar='Cost Optimization',
                        source_service="CloudWatch",
                        affected_resources=[lg['logGroupName']],
                        recommendation="Set appropriate retention (30/90/365 days)",
                        effort="Low",
                        estimated_savings=5
                    ))
        except:
            pass
    
    def _scan_systems_manager(self, region: str):
        """Scan Systems Manager compliance"""
        try:
            ssm = self._get_client('ssm', region_name=region)
            
            # Check compliance
            try:
                compliance = ssm.list_resource_compliance_summaries()
                for item in compliance.get('ResourceComplianceSummaryItems', [])[:20]:
                    if item.get('Status') == 'COMPLIANT':
                        self.inventory.systems_manager_compliant += 1
                    else:
                        self.inventory.systems_manager_noncompliant += 1
            except:
                pass
        except:
            pass
    
    def _scan_eventbridge(self, region: str):
        """Scan EventBridge rules"""
        try:
            eb = self._get_client('events', region_name=region)
            
            rules = eb.list_rules()['Rules']
            self.inventory.eventbridge_rules = len(rules)
        except:
            pass
    
    def _scan_sns(self, region: str):
        """Scan SNS topics"""
        try:
            sns = self._get_client('sns', region_name=region)
            
            topics = sns.list_topics()['Topics']
            self.inventory.sns_topics = len(topics)
        except:
            pass
    
    def _scan_backup(self, region: str):
        """Scan AWS Backup"""
        try:
            backup = self._get_client('backup', region_name=region)
            
            vaults = backup.list_backup_vaults()['BackupVaultList']
            self.inventory.backup_vaults = len(vaults)
            
            plans = backup.list_backup_plans()['BackupPlansList']
            self.inventory.backup_plans = len(plans)
            
            if len(plans) == 0:
                self.findings.append(Finding(
                    id="backup-noplans",
                    title="No AWS Backup Plans Configured",
                    description="Centralized backup service is not being used",
                    severity='MEDIUM',
                    pillar='Reliability',
                    source_service="AWS Backup",
                    affected_resources=[region],
                    recommendation="Create backup plans for critical resources",
                    effort="Medium",
                    compliance_frameworks=["SOC2", "ISO27001"]
                ))
        except:
            pass
    
    def _scan_efs(self, region: str):
        """Scan EFS filesystems"""
        try:
            efs = self._get_client('efs', region_name=region)
            
            filesystems = efs.describe_file_systems()['FileSystems']
            self.inventory.efs_filesystems = len(filesystems)
            
            for fs in filesystems:
                if not fs.get('Encrypted'):
                    self.findings.append(Finding(
                        id=f"efs-noenc-{fs['FileSystemId'][:12]}",
                        title=f"EFS Without Encryption: {fs.get('Name', fs['FileSystemId'])}",
                        description="File system is not encrypted at rest",
                        severity='HIGH',
                        pillar='Security',
                        source_service="EFS",
                        affected_resources=[fs['FileSystemId']],
                        recommendation="Create new encrypted file system and migrate data",
                        effort="High",
                        compliance_frameworks=["HIPAA", "PCI-DSS"]
                    ))
        except:
            pass
    
    def _scan_cloudfront(self):
        """Scan CloudFront distributions"""
        try:
            cf = self._get_client('cloudfront')
            
            distributions = cf.list_distributions()
            if 'DistributionList' in distributions and 'Items' in distributions['DistributionList']:
                distros = distributions['DistributionList']['Items']
                self.inventory.cloudfront_distributions = len(distros)
                
                for distro in distros[:20]:
                    if not distro.get('Logging', {}).get('Enabled'):
                        self.findings.append(Finding(
                            id=f"cf-nolog-{distro['Id'][:12]}",
                            title=f"CloudFront Without Logging: {distro['Id']}",
                            description="Access logging is not enabled",
                            severity='LOW',
                            pillar='Operational Excellence',
                            source_service="CloudFront",
                            affected_resources=[distro['Id']],
                            recommendation="Enable access logging to S3",
                            effort="Low"
                        ))
        except:
            pass
    
    def _scan_route53(self):
        """Scan Route53 zones"""
        try:
            r53 = self._get_client('route53')
            
            zones = r53.list_hosted_zones()['HostedZones']
            self.inventory.route53_zones = len(zones)
        except:
            pass

    # =========================================================================
    # AI/ML SERVICE SCANNING (NEW)
    # =========================================================================
    
    def _scan_sagemaker(self, region: str):
        """Scan Amazon SageMaker resources"""
        try:
            sm = self._get_client('sagemaker', region_name=region)
            
            # Notebooks
            try:
                notebooks = sm.list_notebook_instances()
                self.inventory.sagemaker_notebooks = len(notebooks.get('NotebookInstances', []))
                
                # Check notebook security
                for nb in notebooks.get('NotebookInstances', [])[:10]:
                    nb_name = nb.get('NotebookInstanceName', '')
                    
                    # Check if in VPC
                    if not nb.get('SubnetId'):
                        self.findings.append(Finding(
                            id=f"sm-novpc-{nb_name[:20]}",
                            title=f"SageMaker Notebook Not in VPC: {nb_name}",
                            description="Notebook instance has direct internet access instead of VPC isolation",
                            severity='MEDIUM',
                            pillar='Security',
                            source_service="SageMaker",
                            affected_resources=[nb_name],
                            recommendation="Deploy notebook instances in VPC with private subnets",
                            effort="Medium",
                            compliance_frameworks=["CIS AWS", "SOC 2"]
                        ))
                    
                    # Check root access
                    if nb.get('RootAccess') == 'Enabled':
                        self.findings.append(Finding(
                            id=f"sm-root-{nb_name[:20]}",
                            title=f"SageMaker Notebook Root Access Enabled: {nb_name}",
                            description="Root access is enabled on notebook instance",
                            severity='LOW',
                            pillar='Security',
                            source_service="SageMaker",
                            affected_resources=[nb_name],
                            recommendation="Disable root access unless required",
                            effort="Low"
                        ))
            except:
                pass
            
            # Endpoints
            try:
                endpoints = sm.list_endpoints()
                self.inventory.sagemaker_endpoints = len(endpoints.get('Endpoints', []))
                
                if self.inventory.sagemaker_endpoints > 0:
                    self.inventory.ai_ml_services_detected.append('sagemaker')
                    self.inventory.has_ai_ml_workloads = True
                    
                    # Add finding for model monitoring check
                    self.findings.append(Finding(
                        id="sm-monitor-check",
                        title="Verify SageMaker Model Monitoring Configuration",
                        description=f"Found {self.inventory.sagemaker_endpoints} SageMaker endpoints. Ensure Model Monitor is configured for drift detection.",
                        severity='INFO',
                        pillar='Operational Excellence',
                        source_service="SageMaker",
                        affected_resources=[f"{self.inventory.sagemaker_endpoints} endpoints"],
                        recommendation="Enable SageMaker Model Monitor for production endpoints",
                        effort="Medium"
                    ))
            except:
                pass
            
            # Models
            try:
                models = sm.list_models()
                self.inventory.sagemaker_models = len(models.get('Models', []))
            except:
                pass
            
            # Pipelines
            try:
                pipelines = sm.list_pipelines()
                self.inventory.sagemaker_pipelines = len(pipelines.get('PipelineSummaries', []))
            except:
                pass
                
        except Exception as e:
            self.scan_errors['SageMaker'] = str(e)
    
    def _scan_bedrock(self, region: str):
        """Scan Amazon Bedrock resources"""
        try:
            # Bedrock management
            try:
                bedrock = self._get_client('bedrock', region_name=region)
                
                # List custom models
                try:
                    custom_models = bedrock.list_custom_models()
                    self.inventory.bedrock_models = len(custom_models.get('modelSummaries', []))
                except:
                    pass
                
                # List guardrails
                try:
                    guardrails = bedrock.list_guardrails()
                    self.inventory.bedrock_guardrails = len(guardrails.get('guardrails', []))
                except:
                    pass
            except:
                pass
            
            # Bedrock Agent
            try:
                bedrock_agent = self._get_client('bedrock-agent', region_name=region)
                
                # List agents
                try:
                    agents = bedrock_agent.list_agents()
                    self.inventory.bedrock_agents = len(agents.get('agentSummaries', []))
                    
                    if self.inventory.bedrock_agents > 0:
                        self.inventory.ai_ml_services_detected.append('bedrock')
                        self.inventory.has_ai_ml_workloads = True
                        
                        # Check if guardrails configured
                        if self.inventory.bedrock_guardrails == 0:
                            self.findings.append(Finding(
                                id="bedrock-no-guardrails",
                                title="Bedrock Agents Without Guardrails",
                                description=f"Found {self.inventory.bedrock_agents} Bedrock agents but no guardrails configured",
                                severity='HIGH',
                                pillar='Security',
                                source_service="Bedrock",
                                affected_resources=[f"{self.inventory.bedrock_agents} agents"],
                                recommendation="Configure Bedrock Guardrails for content filtering and safety",
                                remediation_steps=[
                                    "Navigate to Amazon Bedrock console",
                                    "Create guardrails with appropriate content filters",
                                    "Associate guardrails with all agents"
                                ],
                                effort="Medium",
                                compliance_frameworks=["Responsible AI"]
                            ))
                except:
                    pass
                
                # List knowledge bases
                try:
                    kbs = bedrock_agent.list_knowledge_bases()
                    self.inventory.bedrock_knowledge_bases = len(kbs.get('knowledgeBaseSummaries', []))
                except:
                    pass
            except:
                pass
                
        except Exception as e:
            self.scan_errors['Bedrock'] = str(e)
    
    def _scan_ai_services(self, region: str):
        """Scan other AWS AI services (Rekognition, Comprehend, Lex, Kendra)"""
        
        # Rekognition
        try:
            rek = self._get_client('rekognition', region_name=region)
            projects = rek.describe_projects()
            self.inventory.rekognition_projects = len(projects.get('ProjectDescriptions', []))
            if self.inventory.rekognition_projects > 0:
                self.inventory.ai_ml_services_detected.append('rekognition')
                self.inventory.has_ai_ml_workloads = True
                
                # Responsible AI consideration
                self.findings.append(Finding(
                    id="rek-rai-review",
                    title="Rekognition Usage - Review Responsible AI Practices",
                    description=f"Found {self.inventory.rekognition_projects} Rekognition projects. Facial analysis requires careful responsible AI consideration.",
                    severity='INFO',
                    pillar='Security',
                    source_service="Rekognition",
                    affected_resources=[f"{self.inventory.rekognition_projects} projects"],
                    recommendation="Ensure usage complies with responsible AI guidelines and consent requirements",
                    effort="Medium"
                ))
        except:
            pass
        
        # Comprehend
        try:
            comp = self._get_client('comprehend', region_name=region)
            endpoints = comp.list_endpoints()
            self.inventory.comprehend_endpoints = len(endpoints.get('EndpointPropertiesList', []))
            if self.inventory.comprehend_endpoints > 0:
                self.inventory.ai_ml_services_detected.append('comprehend')
                self.inventory.has_ai_ml_workloads = True
        except:
            pass
        
        # Lex
        try:
            lex = self._get_client('lexv2-models', region_name=region)
            bots = lex.list_bots()
            self.inventory.lex_bots = len(bots.get('botSummaries', []))
            if self.inventory.lex_bots > 0:
                self.inventory.ai_ml_services_detected.append('lex')
                self.inventory.has_ai_ml_workloads = True
        except:
            pass
        
        # Kendra
        try:
            kendra = self._get_client('kendra', region_name=region)
            indexes = kendra.list_indices()
            self.inventory.kendra_indexes = len(indexes.get('IndexConfigurationSummaryItems', []))
            if self.inventory.kendra_indexes > 0:
                self.inventory.ai_ml_services_detected.append('kendra')
                self.inventory.has_ai_ml_workloads = True
        except:
            pass


    # =============================================================================
    # ADDITIONAL SERVICE SCAN METHODS - Complete WAF Coverage
    # =============================================================================
    
    def _scan_acm(self, region: str):
        """Scan AWS Certificate Manager for certificate issues"""
        try:
            acm = self._get_client('acm', region_name=region)
            certs = acm.list_certificates().get('CertificateSummaryList', [])
            
            for cert in certs:
                cert_arn = cert['CertificateArn']
                try:
                    details = acm.describe_certificate(CertificateArn=cert_arn)['Certificate']
                    
                    if details.get('NotAfter'):
                        from datetime import datetime, timezone
                        days_until_expiry = (details['NotAfter'].replace(tzinfo=None) - datetime.utcnow()).days
                        if days_until_expiry < 30:
                            self.findings.append(Finding(
                                id=f"acm-expiring-{cert['DomainName'][:20]}",
                                title=f"Certificate Expiring Soon: {cert['DomainName']}",
                                description=f"SSL certificate expires in {days_until_expiry} days",
                                severity='HIGH' if days_until_expiry < 7 else 'MEDIUM',
                                pillar='Security',
                                source_service="ACM",
                                affected_resources=[cert['DomainName']],
                                recommendation="Renew or replace the certificate before expiration",
                                effort="Low"
                            ))
                except:
                    pass
        except Exception as e:
            self.scan_errors['ACM'] = str(e)

    def _scan_api_gateway(self, region: str):
        """Scan API Gateway for security configurations"""
        try:
            apigw = self._get_client('apigateway', region_name=region)
            apis = apigw.get_rest_apis().get('items', [])
            
            for api in apis:
                api_id = api['id']
                api_name = api['name']
                
                try:
                    stages = apigw.get_stages(restApiId=api_id).get('item', [])
                    for stage in stages:
                        if not stage.get('webAclArn'):
                            self.findings.append(Finding(
                                id=f"apigw-nowaf-{api_id[:10]}",
                                title=f"API Gateway Without WAF: {api_name}",
                                description="API Gateway stage is not protected by AWS WAF",
                                severity='MEDIUM',
                                pillar='Security',
                                source_service="API Gateway",
                                affected_resources=[f"{api_name}/{stage['stageName']}"],
                                recommendation="Associate AWS WAF WebACL with the API Gateway stage",
                                effort="Medium"
                            ))
                except:
                    pass
        except Exception as e:
            self.scan_errors['API Gateway'] = str(e)

    def _scan_cognito(self, region: str):
        """Scan Cognito user pools for security settings"""
        try:
            cognito = self._get_client('cognito-idp', region_name=region)
            pools = cognito.list_user_pools(MaxResults=60).get('UserPools', [])
            
            for pool in pools:
                pool_id = pool['Id']
                try:
                    pool_details = cognito.describe_user_pool(UserPoolId=pool_id)['UserPool']
                    
                    mfa_config = pool_details.get('MfaConfiguration', 'OFF')
                    if mfa_config == 'OFF':
                        self.findings.append(Finding(
                            id=f"cognito-nomfa-{pool_id[:10]}",
                            title=f"Cognito User Pool Without MFA: {pool['Name']}",
                            description="MFA is not enabled for user authentication",
                            severity='HIGH',
                            pillar='Security',
                            source_service="Cognito",
                            affected_resources=[pool['Name']],
                            recommendation="Enable MFA (OPTIONAL or REQUIRED) for user pool",
                            effort="Medium"
                        ))
                except:
                    pass
        except Exception as e:
            self.scan_errors['Cognito'] = str(e)

    def _scan_inspector(self, region: str):
        """Scan Inspector for vulnerability status"""
        try:
            inspector = self._get_client('inspector2', region_name=region)
            
            try:
                status = inspector.batch_get_account_status(accountIds=[self.account_id] if self.account_id else [])
                accounts = status.get('accounts', [])
                if not accounts or accounts[0].get('state', {}).get('status') != 'ENABLED':
                    self.findings.append(Finding(
                        id="inspector-disabled",
                        title="Amazon Inspector Not Enabled",
                        description="Inspector is not enabled for vulnerability scanning",
                        severity='MEDIUM',
                        pillar='Security',
                        source_service="Inspector",
                        affected_resources=[self.account_id or 'Account'],
                        recommendation="Enable Amazon Inspector for automated vulnerability assessment",
                        effort="Low"
                    ))
            except:
                pass
        except Exception as e:
            self.scan_errors['Inspector'] = str(e)

    def _scan_macie(self, region: str):
        """Scan Macie for data discovery status"""
        try:
            macie = self._get_client('macie2', region_name=region)
            
            try:
                status = macie.get_macie_session()
                if status.get('status') != 'ENABLED':
                    self.findings.append(Finding(
                        id="macie-disabled",
                        title="Amazon Macie Not Enabled",
                        description="Macie is not enabled for sensitive data discovery",
                        severity='MEDIUM',
                        pillar='Security',
                        source_service="Macie",
                        affected_resources=[self.account_id or 'Account'],
                        recommendation="Enable Amazon Macie for automated sensitive data discovery",
                        effort="Low"
                    ))
            except:
                pass
        except Exception as e:
            self.scan_errors['Macie'] = str(e)

    def _scan_organizations(self):
        """Scan AWS Organizations for SCPs"""
        try:
            org = self._get_client('organizations')
            
            try:
                org_info = org.describe_organization()['Organization']
                policies = org.list_policies(Filter='SERVICE_CONTROL_POLICY')['Policies']
                if len(policies) <= 1:
                    self.findings.append(Finding(
                        id="org-noscp",
                        title="No Custom Service Control Policies",
                        description="Only default FullAWSAccess SCP is in use",
                        severity='MEDIUM',
                        pillar='Security',
                        source_service="Organizations",
                        affected_resources=[org_info['Id']],
                        recommendation="Implement SCPs to enforce security guardrails",
                        effort="Medium"
                    ))
            except:
                pass
        except Exception as e:
            self.scan_errors['Organizations'] = str(e)

    def _scan_sqs(self, region: str):
        """Scan SQS queues for security"""
        try:
            sqs = self._get_client('sqs', region_name=region)
            queues = sqs.list_queues().get('QueueUrls', [])
            self.inventory.sqs_queues = len(queues)
            
            for queue_url in queues[:20]:
                try:
                    attrs = sqs.get_queue_attributes(QueueUrl=queue_url, AttributeNames=['All'])['Attributes']
                    
                    if not attrs.get('KmsMasterKeyId') and not attrs.get('SqsManagedSseEnabled'):
                        queue_name = queue_url.split('/')[-1]
                        self.findings.append(Finding(
                            id=f"sqs-noenc-{queue_name[:15]}",
                            title=f"SQS Queue Not Encrypted: {queue_name}",
                            description="Queue does not have server-side encryption enabled",
                            severity='MEDIUM',
                            pillar='Security',
                            source_service="SQS",
                            affected_resources=[queue_name],
                            recommendation="Enable SSE-SQS or SSE-KMS encryption",
                            effort="Low"
                        ))
                except:
                    pass
        except Exception as e:
            self.scan_errors['SQS'] = str(e)

    def _scan_step_functions(self, region: str):
        """Scan Step Functions"""
        try:
            sfn = self._get_client('stepfunctions', region_name=region)
            machines = sfn.list_state_machines().get('stateMachines', [])
            
            for machine in machines:
                try:
                    details = sfn.describe_state_machine(stateMachineArn=machine['stateMachineArn'])
                    logging_config = details.get('loggingConfiguration', {})
                    if logging_config.get('level') == 'OFF':
                        self.findings.append(Finding(
                            id=f"sfn-nolog-{machine['name'][:15]}",
                            title=f"Step Function Without Logging: {machine['name']}",
                            description="CloudWatch logging is disabled for state machine",
                            severity='LOW',
                            pillar='Operational Excellence',
                            source_service="Step Functions",
                            affected_resources=[machine['name']],
                            recommendation="Enable CloudWatch logging for state machine",
                            effort="Low"
                        ))
                except:
                    pass
        except Exception as e:
            self.scan_errors['Step Functions'] = str(e)

    def _scan_xray(self, region: str):
        """Scan X-Ray configuration"""
        try:
            xray = self._get_client('xray', region_name=region)
            rules = xray.get_sampling_rules().get('SamplingRuleRecords', [])
            if len(rules) <= 1:
                self.findings.append(Finding(
                    id="xray-defaultonly",
                    title="X-Ray Using Only Default Sampling",
                    description="No custom sampling rules configured",
                    severity='LOW',
                    pillar='Operational Excellence',
                    source_service="X-Ray",
                    affected_resources=[region],
                    recommendation="Configure custom sampling rules for important services",
                    effort="Low"
                ))
        except Exception as e:
            self.scan_errors['X-Ray'] = str(e)

    def _scan_compute_optimizer(self, region: str):
        """Scan Compute Optimizer recommendations"""
        try:
            co = self._get_client('compute-optimizer', region_name=region)
            
            try:
                status = co.get_enrollment_status()
                if status.get('status') != 'Active':
                    self.findings.append(Finding(
                        id="co-notenrolled",
                        title="Compute Optimizer Not Enrolled",
                        description="Account is not enrolled in AWS Compute Optimizer",
                        severity='LOW',
                        pillar='Cost Optimization',
                        source_service="Compute Optimizer",
                        affected_resources=[self.account_id or 'Account'],
                        recommendation="Enable Compute Optimizer for rightsizing recommendations",
                        effort="Low"
                    ))
            except:
                pass
        except Exception as e:
            self.scan_errors['Compute Optimizer'] = str(e)

    def _scan_trusted_advisor(self):
        """Scan Trusted Advisor recommendations"""
        try:
            support = self._get_client('support', region_name='us-east-1')
            
            checks = support.describe_trusted_advisor_checks(language='en')['checks']
            
            for check in checks[:20]:
                try:
                    result = support.describe_trusted_advisor_check_result(checkId=check['id'])['result']
                    if result['status'] in ['warning', 'error']:
                        pillar_map = {
                            'cost_optimizing': 'Cost Optimization',
                            'security': 'Security',
                            'fault_tolerance': 'Reliability',
                            'performance': 'Performance Efficiency'
                        }
                        pillar = pillar_map.get(check.get('category'), 'Operational Excellence')
                        
                        self.findings.append(Finding(
                            id=f"ta-{check['id'][:10]}",
                            title=f"Trusted Advisor: {check['name']}",
                            description=check.get('description', '')[:200],
                            severity='HIGH' if result['status'] == 'error' else 'MEDIUM',
                            pillar=pillar,
                            source_service="Trusted Advisor",
                            affected_resources=[],
                            recommendation=check.get('description', '')[:200],
                            effort="Medium"
                        ))
                except:
                    pass
        except Exception as e:
            self.scan_errors['Trusted Advisor'] = str(e)

    def _scan_budgets(self):
        """Scan AWS Budgets"""
        try:
            budgets = self._get_client('budgets')
            
            budget_list = budgets.describe_budgets(AccountId=self.account_id).get('Budgets', [])
            
            if not budget_list:
                self.findings.append(Finding(
                    id="budgets-none",
                    title="No AWS Budgets Configured",
                    description="No cost budgets are configured for cost monitoring",
                    severity='MEDIUM',
                    pillar='Cost Optimization',
                    source_service="Budgets",
                    affected_resources=[self.account_id or 'Account'],
                    recommendation="Create AWS Budgets with alerts for cost management",
                    effort="Low"
                ))
        except Exception as e:
            self.scan_errors['Budgets'] = str(e)

    def _scan_cost_anomaly(self):
        """Scan Cost Anomaly Detection"""
        try:
            ce = self._get_client('ce')
            monitors = ce.get_anomaly_monitors().get('AnomalyMonitors', [])
            
            if not monitors:
                self.findings.append(Finding(
                    id="costanomaly-none",
                    title="Cost Anomaly Detection Not Configured",
                    description="No cost anomaly monitors are set up",
                    severity='LOW',
                    pillar='Cost Optimization',
                    source_service="Cost Anomaly Detection",
                    affected_resources=[self.account_id or 'Account'],
                    recommendation="Set up Cost Anomaly Detection monitors",
                    effort="Low"
                ))
        except Exception as e:
            self.scan_errors['Cost Anomaly Detection'] = str(e)

    def _scan_transit_gateway(self, region: str):
        """Scan Transit Gateways"""
        try:
            ec2 = self._get_client('ec2', region_name=region)
            tgws = ec2.describe_transit_gateways().get('TransitGateways', [])
            self.inventory.transit_gateways = len(tgws)
        except Exception as e:
            self.scan_errors['Transit Gateway'] = str(e)

    def _scan_direct_connect(self, region: str):
        """Scan Direct Connect connections"""
        try:
            dx = self._get_client('directconnect', region_name=region)
            connections = dx.describe_connections().get('connections', [])
            
            for conn in connections:
                if conn.get('connectionState') == 'available':
                    location_conns = [c for c in connections if c.get('location') == conn.get('location')]
                    if len(location_conns) == 1:
                        self.findings.append(Finding(
                            id=f"dx-nored-{conn['connectionId'][:15]}",
                            title=f"Direct Connect Without Redundancy: {conn['connectionName']}",
                            description="Single Direct Connect connection without failover",
                            severity='MEDIUM',
                            pillar='Reliability',
                            source_service="Direct Connect",
                            affected_resources=[conn['connectionName']],
                            recommendation="Add redundant Direct Connect or VPN backup",
                            effort="High"
                        ))
        except Exception as e:
            self.scan_errors['Direct Connect'] = str(e)

    def _scan_global_accelerator(self):
        """Scan Global Accelerator"""
        try:
            ga = self._get_client('globalaccelerator', region_name='us-west-2')
            accelerators = ga.list_accelerators().get('Accelerators', [])
            
            for acc in accelerators:
                if not acc.get('Enabled'):
                    self.findings.append(Finding(
                        id=f"ga-disabled-{acc['AcceleratorArn'][-10:]}",
                        title=f"Global Accelerator Disabled: {acc['Name']}",
                        description="Global Accelerator is not enabled",
                        severity='LOW',
                        pillar='Performance Efficiency',
                        source_service="Global Accelerator",
                        affected_resources=[acc['Name']],
                        recommendation="Enable or delete unused Global Accelerator",
                        effort="Low"
                    ))
        except Exception as e:
            self.scan_errors['Global Accelerator'] = str(e)

    def _scan_codepipeline(self, region: str):
        """Scan CodePipeline"""
        try:
            cp = self._get_client('codepipeline', region_name=region)
            pipelines = cp.list_pipelines().get('pipelines', [])
            
            for pipeline in pipelines:
                try:
                    details = cp.get_pipeline(name=pipeline['name'])['pipeline']
                    has_approval = any(
                        action.get('actionTypeId', {}).get('category') == 'Approval'
                        for stage in details.get('stages', [])
                        for action in stage.get('actions', [])
                    )
                    
                    if not has_approval:
                        self.findings.append(Finding(
                            id=f"cp-noapproval-{pipeline['name'][:15]}",
                            title=f"Pipeline Without Approval: {pipeline['name']}",
                            description="Pipeline has no manual approval stage",
                            severity='MEDIUM',
                            pillar='Operational Excellence',
                            source_service="CodePipeline",
                            affected_resources=[pipeline['name']],
                            recommendation="Add approval action before production deployment",
                            effort="Low"
                        ))
                except:
                    pass
        except Exception as e:
            self.scan_errors['CodePipeline'] = str(e)

    def _scan_codebuild(self, region: str):
        """Scan CodeBuild projects"""
        try:
            cb = self._get_client('codebuild', region_name=region)
            projects = cb.list_projects().get('projects', [])
            
            for project_name in projects[:20]:
                try:
                    project = cb.batch_get_projects(names=[project_name])['projects'][0]
                    
                    if not project.get('encryptionKey'):
                        self.findings.append(Finding(
                            id=f"cb-noenc-{project_name[:15]}",
                            title=f"CodeBuild Without Custom Encryption: {project_name}",
                            description="CodeBuild project uses default encryption",
                            severity='LOW',
                            pillar='Security',
                            source_service="CodeBuild",
                            affected_resources=[project_name],
                            recommendation="Configure custom KMS key for encryption",
                            effort="Low"
                        ))
                except:
                    pass
        except Exception as e:
            self.scan_errors['CodeBuild'] = str(e)

    def _scan_vpc_detailed(self, region: str):
        """Detailed VPC scanning including subnets, NACLs, endpoints"""
        try:
            ec2 = self._get_client('ec2', region_name=region)
            
            # VPCs
            vpcs = ec2.describe_vpcs().get('Vpcs', [])
            self.inventory.vpcs = len(vpcs)
            
            # Subnets
            subnets = ec2.describe_subnets().get('Subnets', [])
            self.inventory.subnets = len(subnets)
            
            # Security Groups
            sgs = ec2.describe_security_groups().get('SecurityGroups', [])
            self.inventory.security_groups = len(sgs)
            
            for sg in sgs:
                for rule in sg.get('IpPermissions', []):
                    for ip_range in rule.get('IpRanges', []):
                        if ip_range.get('CidrIp') == '0.0.0.0/0':
                            port = rule.get('FromPort', 'All')
                            if port in [22, 3389, 3306, 5432, 1433, 27017]:
                                self.inventory.security_groups_open += 1
                                self.findings.append(Finding(
                                    id=f"sg-open-{sg['GroupId'][:10]}-{port}",
                                    title=f"Security Group Open to Internet: {sg.get('GroupName', sg['GroupId'])} (Port {port})",
                                    description=f"Port {port} is accessible from 0.0.0.0/0",
                                    severity='CRITICAL' if port in [22, 3389] else 'HIGH',
                                    pillar='Security',
                                    source_service="VPC",
                                    affected_resources=[sg.get('GroupName', sg['GroupId'])],
                                    recommendation=f"Restrict port {port} access to specific IP ranges",
                                    effort="Low",
                                    compliance_frameworks=["CIS AWS", "PCI-DSS"]
                                ))
            
            # NACLs
            nacls = ec2.describe_network_acls().get('NetworkAcls', [])
            self.inventory.nacls = len(nacls)
            
            # VPC Endpoints
            endpoints = ec2.describe_vpc_endpoints().get('VpcEndpoints', [])
            self.inventory.vpc_endpoints = len(endpoints)
            
            # NAT Gateways
            nat_gws = ec2.describe_nat_gateways().get('NatGateways', [])
            self.inventory.nat_gateways = len([n for n in nat_gws if n.get('State') == 'available'])
            
        except Exception as e:
            self.scan_errors['VPC Detailed'] = str(e)

    def _scan_cloudwatch_detailed(self, region: str):
        """Detailed CloudWatch scanning"""
        try:
            cw = self._get_client('cloudwatch', region_name=region)
            logs = self._get_client('logs', region_name=region)
            
            # Alarms
            alarms = cw.describe_alarms().get('MetricAlarms', [])
            self.inventory.cloudwatch_alarms = len(alarms)
            
            # Log Groups
            log_groups = logs.describe_log_groups().get('logGroups', [])
            self.inventory.cloudwatch_log_groups = len(log_groups)
            
            # Check for log groups without retention
            for lg in log_groups[:30]:
                if not lg.get('retentionInDays'):
                    self.findings.append(Finding(
                        id=f"cwl-noretention-{lg['logGroupName'][:20]}",
                        title=f"Log Group Without Retention: {lg['logGroupName'][:40]}",
                        description="Log group has no retention policy (logs kept forever)",
                        severity='LOW',
                        pillar='Cost Optimization',
                        source_service="CloudWatch",
                        affected_resources=[lg['logGroupName']],
                        recommendation="Set appropriate retention policy to manage costs",
                        effort="Low"
                    ))
        except Exception as e:
            self.scan_errors['CloudWatch Detailed'] = str(e)

    def _scan_service_catalog(self, region: str):
        """Scan Service Catalog"""
        try:
            sc = self._get_client('servicecatalog', region_name=region)
            portfolios = sc.list_portfolios().get('PortfolioDetails', [])
            # Just inventory for now
        except Exception as e:
            self.scan_errors['Service Catalog'] = str(e)

    def _scan_control_tower(self, region: str):
        """Scan Control Tower status"""
        try:
            ct = self._get_client('controltower', region_name=region)
            # Control Tower scanning
        except Exception as e:
            self.scan_errors['Control Tower'] = str(e)

    def _scan_dax(self, region: str):
        """Scan DAX clusters"""
        try:
            dax = self._get_client('dax', region_name=region)
            clusters = dax.describe_clusters().get('Clusters', [])
            
            for cluster in clusters:
                if not cluster.get('SSEDescription', {}).get('Status') == 'ENABLED':
                    self.findings.append(Finding(
                        id=f"dax-nosse-{cluster['ClusterName'][:15]}",
                        title=f"DAX Cluster Not Encrypted: {cluster['ClusterName']}",
                        description="DAX cluster does not have encryption at rest enabled",
                        severity='MEDIUM',
                        pillar='Security',
                        source_service="DAX",
                        affected_resources=[cluster['ClusterName']],
                        recommendation="Enable server-side encryption for DAX cluster",
                        effort="Medium"
                    ))
        except Exception as e:
            self.scan_errors['DAX'] = str(e)


    def _scan_cloudformation(self, region: str):
        """Scan CloudFormation stacks"""
        try:
            cfn = self._get_client('cloudformation', region_name=region)
            stacks = cfn.describe_stacks().get('Stacks', [])
            
            for stack in stacks:
                if stack.get('EnableTerminationProtection') == False:
                    self.findings.append(Finding(
                        id=f"cfn-noprotect-{stack['StackName'][:15]}",
                        title=f"Stack Without Termination Protection: {stack['StackName']}",
                        description="CloudFormation stack can be accidentally deleted",
                        severity='LOW',
                        pillar='Reliability',
                        source_service="CloudFormation",
                        affected_resources=[stack['StackName']],
                        recommendation="Enable termination protection for production stacks",
                        effort="Low"
                    ))
        except Exception as e:
            self.scan_errors['CloudFormation'] = str(e)

    def _scan_cost_explorer(self):
        """Scan Cost Explorer for cost insights"""
        try:
            ce = self._get_client('ce')
            # Cost Explorer is used for recommendations - checking if data is available
            # Note: Cost Explorer requires permissions and may have costs
        except Exception as e:
            self.scan_errors['Cost Explorer'] = str(e)

    def _scan_fsx(self, region: str):
        """Scan FSx file systems"""
        try:
            fsx = self._get_client('fsx', region_name=region)
            filesystems = fsx.describe_file_systems().get('FileSystems', [])
            
            for fs in filesystems:
                if not fs.get('KmsKeyId'):
                    self.findings.append(Finding(
                        id=f"fsx-noenc-{fs['FileSystemId'][:15]}",
                        title=f"FSx Without Customer KMS Key: {fs['FileSystemId']}",
                        description="FSx file system uses default encryption key",
                        severity='LOW',
                        pillar='Security',
                        source_service="FSx",
                        affected_resources=[fs['FileSystemId']],
                        recommendation="Consider using customer-managed KMS key",
                        effort="Medium"
                    ))
        except Exception as e:
            self.scan_errors['FSx'] = str(e)

    def _scan_glacier(self, region: str):
        """Scan Glacier vaults"""
        try:
            glacier = self._get_client('glacier', region_name=region)
            vaults = glacier.list_vaults().get('VaultList', [])
            # Glacier inventory
        except Exception as e:
            self.scan_errors['Glacier'] = str(e)

    def _scan_shield(self, region: str):
        """Scan Shield Advanced status"""
        try:
            shield = self._get_client('shield', region_name='us-east-1')
            
            try:
                subscription = shield.get_subscription_state()
                if subscription.get('SubscriptionState') == 'ACTIVE':
                    self.inventory.shield_advanced = True
            except:
                pass
        except Exception as e:
            self.scan_errors['Shield'] = str(e)

    def _scan_devops_guru(self, region: str):
        """Scan DevOps Guru status"""
        try:
            devopsguru = self._get_client('devops-guru', region_name=region)
            
            try:
                health = devopsguru.describe_account_health()
                # DevOps Guru is enabled if we can query it
            except:
                self.findings.append(Finding(
                    id="devopsguru-notsetup",
                    title="DevOps Guru Not Configured",
                    description="Amazon DevOps Guru is not enabled for AIOps insights",
                    severity='LOW',
                    pillar='Operational Excellence',
                    source_service="DevOps Guru",
                    affected_resources=[region],
                    recommendation="Enable DevOps Guru for ML-powered operational insights",
                    effort="Low"
                ))
        except Exception as e:
            self.scan_errors['DevOps Guru'] = str(e)

    def _scan_fis(self, region: str):
        """Scan Fault Injection Simulator"""
        try:
            fis = self._get_client('fis', region_name=region)
            experiments = fis.list_experiments().get('experiments', [])
            # FIS inventory - having experiments is good for chaos engineering
        except Exception as e:
            self.scan_errors['FIS'] = str(e)

    def _scan_app_mesh(self, region: str):
        """Scan App Mesh"""
        try:
            appmesh = self._get_client('appmesh', region_name=region)
            meshes = appmesh.list_meshes().get('meshes', [])
            # App Mesh inventory
        except Exception as e:
            self.scan_errors['App Mesh'] = str(e)

    def _scan_service_health(self):
        """Check Service Health Dashboard events"""
        try:
            health = self._get_client('health', region_name='us-east-1')
            events = health.describe_events(filter={'eventStatusCodes': ['open', 'upcoming']}).get('events', [])
            
            for event in events:
                self.findings.append(Finding(
                    id=f"health-{event['arn'][-15:]}",
                    title=f"AWS Service Event: {event.get('service', 'Unknown')}",
                    description=event.get('eventTypeCode', 'Service event detected'),
                    severity='MEDIUM',
                    pillar='Reliability',
                    source_service="Service Health Dashboard",
                    affected_resources=[event.get('service', 'Unknown')],
                    recommendation="Monitor the AWS Health Dashboard for updates",
                    effort="Low"
                ))
        except Exception as e:
            self.scan_errors['Service Health Dashboard'] = str(e)

    def _scan_parameter_store(self, region: str):
        """Scan Parameter Store"""
        try:
            ssm = self._get_client('ssm', region_name=region)
            params = ssm.describe_parameters(MaxResults=50).get('Parameters', [])
            
            for param in params:
                if param.get('Type') != 'SecureString' and 'password' in param.get('Name', '').lower():
                    self.findings.append(Finding(
                        id=f"ssm-insecure-{param['Name'][:15]}",
                        title=f"Potentially Sensitive Parameter Not Encrypted: {param['Name']}",
                        description="Parameter with 'password' in name is not SecureString",
                        severity='HIGH',
                        pillar='Security',
                        source_service="Parameter Store",
                        affected_resources=[param['Name']],
                        recommendation="Convert to SecureString parameter type",
                        effort="Low"
                    ))
        except Exception as e:
            self.scan_errors['Parameter Store'] = str(e)

    def _scan_iam_access_analyzer(self, region: str):
        """Scan IAM Access Analyzer"""
        try:
            aa = self._get_client('accessanalyzer', region_name=region)
            analyzers = aa.list_analyzers().get('analyzers', [])
            
            if not analyzers:
                self.findings.append(Finding(
                    id="aa-notsetup",
                    title="IAM Access Analyzer Not Enabled",
                    description="No IAM Access Analyzer configured in this region",
                    severity='MEDIUM',
                    pillar='Security',
                    source_service="IAM Access Analyzer",
                    affected_resources=[region],
                    recommendation="Enable IAM Access Analyzer to identify external access",
                    effort="Low"
                ))
            else:
                # Check for active findings
                for analyzer in analyzers:
                    findings_list = aa.list_findings(analyzerArn=analyzer['arn']).get('findings', [])
                    active = [f for f in findings_list if f.get('status') == 'ACTIVE']
                    if len(active) > 5:
                        self.findings.append(Finding(
                            id=f"aa-findings-{len(active)}",
                            title=f"IAM Access Analyzer: {len(active)} Active Findings",
                            description="Multiple external access findings detected",
                            severity='HIGH',
                            pillar='Security',
                            source_service="IAM Access Analyzer",
                            affected_resources=[f['resource'] for f in active[:5]],
                            recommendation="Review and remediate Access Analyzer findings",
                            effort="Medium"
                        ))
        except Exception as e:
            self.scan_errors['IAM Access Analyzer'] = str(e)

# =============================================================================
# COMPREHENSIVE run_scan METHOD - 50+ Services
# =============================================================================

    def run_scan(self, regions: List[str], progress_callback: Callable = None, use_cache: bool = True, cache_ttl: int = 300) -> LandscapeAssessment:
        """
        Run comprehensive scan with 60+ AWS services - ENHANCED VERSION
        
        Args:
            regions: List of AWS regions to scan
            progress_callback: Optional callback for progress updates
            use_cache: Whether to use cached results if available (default True)
            cache_ttl: Cache time-to-live in seconds (default 5 minutes)
        
        Returns:
            LandscapeAssessment with all findings and scores
        """
        
        # Check for cached results
        cache_key = f"_landscape_scan_{self.account_id}_{','.join(sorted(regions))}"
        
        if use_cache and cache_key in st.session_state:
            cached = st.session_state[cache_key]
            if isinstance(cached, dict) and 'timestamp' in cached:
                age = (datetime.now() - cached['timestamp']).total_seconds()
                if age < cache_ttl:
                    # Return cached result
                    return cached['data']
        
        start_time = datetime.now()
        
        # COMPREHENSIVE SCAN TASKS - 60+ services for complete WAF coverage
        scan_tasks = [
            # ===== SECURITY (18 services) =====
            ("IAM", self._scan_iam),
            ("KMS", self._scan_kms),
            ("Secrets Manager", self._scan_secrets_manager),
            ("GuardDuty", lambda: self._scan_guardduty(regions[0])),
            ("Security Hub", lambda: self._scan_securityhub(regions[0])),
            ("Config", lambda: self._scan_config(regions[0])),
            ("CloudTrail", lambda: self._scan_cloudtrail(regions[0])),
            ("WAF", lambda: self._scan_waf(regions[0])),
            ("ACM", lambda: self._scan_acm(regions[0])),
            ("Inspector", lambda: self._scan_inspector(regions[0])),
            ("Macie", lambda: self._scan_macie(regions[0])),
            ("Organizations", self._scan_organizations),
            ("Cognito", lambda: self._scan_cognito(regions[0])),
            ("Shield", lambda: self._scan_shield(regions[0])),
            ("IAM Access Analyzer", lambda: self._scan_iam_access_analyzer(regions[0])),
            ("Parameter Store", lambda: self._scan_parameter_store(regions[0])),
            
            # ===== COMPUTE (6 services) =====
            ("EC2", lambda: self._scan_ec2(regions[0])),
            ("Lambda", lambda: self._scan_lambda(regions[0])),
            ("ECS", lambda: self._scan_ecs(regions[0])),
            ("EKS", lambda: self._scan_eks(regions[0])),
            ("Auto Scaling", lambda: self._scan_autoscaling(regions[0])),
            
            # ===== STORAGE (5 services) =====
            ("S3", self._scan_s3),
            ("EBS", lambda: self._scan_ebs_volumes(regions[0])),
            ("EFS", lambda: self._scan_efs(regions[0])),
            ("FSx", lambda: self._scan_fsx(regions[0])),
            ("Glacier", lambda: self._scan_glacier(regions[0])),
            
            # ===== DATABASE (4 services) =====
            ("RDS", lambda: self._scan_rds(regions[0])),
            ("DynamoDB", lambda: self._scan_dynamodb(regions[0])),
            ("ElastiCache", lambda: self._scan_elasticache(regions[0])),
            ("DAX", lambda: self._scan_dax(regions[0])),
            
            # ===== NETWORKING (9 services) =====
            ("VPC", lambda: self._scan_vpc_detailed(regions[0])),
            ("ELB", lambda: self._scan_elb(regions[0])),
            ("CloudFront", self._scan_cloudfront),
            ("Route 53", self._scan_route53),
            ("API Gateway", lambda: self._scan_api_gateway(regions[0])),
            ("Transit Gateway", lambda: self._scan_transit_gateway(regions[0])),
            ("Direct Connect", lambda: self._scan_direct_connect(regions[0])),
            ("Global Accelerator", self._scan_global_accelerator),
            ("App Mesh", lambda: self._scan_app_mesh(regions[0])),
            
            # ===== MONITORING & OPS (12 services) =====
            ("CloudWatch", lambda: self._scan_cloudwatch_detailed(regions[0])),
            ("Systems Manager", lambda: self._scan_systems_manager(regions[0])),
            ("EventBridge", lambda: self._scan_eventbridge(regions[0])),
            ("SNS", lambda: self._scan_sns(regions[0])),
            ("SQS", lambda: self._scan_sqs(regions[0])),
            ("X-Ray", lambda: self._scan_xray(regions[0])),
            ("Step Functions", lambda: self._scan_step_functions(regions[0])),
            ("CloudFormation", lambda: self._scan_cloudformation(regions[0])),
            ("DevOps Guru", lambda: self._scan_devops_guru(regions[0])),
            ("FIS", lambda: self._scan_fis(regions[0])),
            ("Service Health Dashboard", self._scan_service_health),
            
            # ===== CI/CD (3 services) =====
            ("CodePipeline", lambda: self._scan_codepipeline(regions[0])),
            ("CodeBuild", lambda: self._scan_codebuild(regions[0])),
            
            # ===== COST (5 services) =====
            ("AWS Backup", lambda: self._scan_backup(regions[0])),
            ("Budgets", self._scan_budgets),
            ("Cost Anomaly Detection", self._scan_cost_anomaly),
            ("Compute Optimizer", lambda: self._scan_compute_optimizer(regions[0])),
            ("Trusted Advisor", self._scan_trusted_advisor),
            ("Cost Explorer", self._scan_cost_explorer),
            
            # ===== AI/ML (3 services) =====
            ("SageMaker", lambda: self._scan_sagemaker(regions[0])),
            ("Bedrock", lambda: self._scan_bedrock(regions[0])),
            ("AI Services", lambda: self._scan_ai_services(regions[0])),
        ]
        
        # Execute scans
        total_tasks = len(scan_tasks)
        
        for idx, (name, func) in enumerate(scan_tasks):
            if progress_callback:
                progress_callback(idx / total_tasks, f"Scanning {name}...")
            
            try:
                func()
                self.scan_status[name] = True
            except Exception as e:
                self.scan_status[name] = False
                self.scan_errors[name] = str(e)
        
        if progress_callback:
            progress_callback(1.0, "Calculating scores...")
        
        # Build assessment
        pillar_scores = self._calculate_pillar_scores()
        overall_score = self._calculate_overall_score(pillar_scores)
        
        # Calculate AI/ML health score
        aiml_health = self._calculate_aiml_health_score()
        aiml_findings = [f for f in self.findings if f.source_service in 
                        ['SageMaker', 'Bedrock', 'Rekognition', 'Comprehend', 'Lex', 'Kendra', 'Personalize']]
        
        # Build assessment result
        assessment = LandscapeAssessment(
            assessment_id=f"scan-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
            timestamp=datetime.now(),
            accounts_scanned=[self.account_id] if self.account_id else [],
            regions_scanned=regions,
            overall_score=overall_score,
            overall_risk=self._determine_risk(overall_score),
            inventory=self.inventory,
            pillar_scores=pillar_scores,
            findings=self.findings,
            services_scanned=self.scan_status,
            scan_errors=self.scan_errors,
            scan_duration_seconds=(datetime.now() - start_time).total_seconds(),
            aiml_health_score=aiml_health,
            aiml_findings=aiml_findings
        )
        
        # Cache the result for future use
        if use_cache:
            st.session_state[cache_key] = {
                'data': assessment,
                'timestamp': datetime.now()
            }
        
        return assessment




    def _calculate_pillar_scores(self) -> Dict[str, PillarScore]:
        """Calculate pillar scores"""
        pillar_scores = {}
        pillars = ['Security', 'Reliability', 'Performance Efficiency', 'Cost Optimization', 'Operational Excellence', 'Sustainability']
        
        for pillar in pillars:
            pfindings = [f for f in self.findings if f.pillar == pillar]
            critical = sum(1 for f in pfindings if f.severity == 'CRITICAL')
            high = sum(1 for f in pfindings if f.severity == 'HIGH')
            medium = sum(1 for f in pfindings if f.severity == 'MEDIUM')
            low = sum(1 for f in pfindings if f.severity in ['LOW', 'INFO'])
            
            score = 100 - (critical * 20) - (high * 10) - (medium * 5) - (low * 2)
            score = max(0, min(100, score))
            
            pillar_scores[pillar] = PillarScore(
                name=pillar,
                score=score,
                findings_count=len(pfindings),
                critical_count=critical,
                high_count=high,
                medium_count=medium,
                low_count=low,
                top_findings=pfindings[:5]
            )
        
        return pillar_scores
    
    def _calculate_overall_score(self, pillar_scores: Dict[str, PillarScore]) -> int:
        """Calculate overall score"""
        weights = {'Security': 1.5, 'Reliability': 1.3, 'Performance Efficiency': 1.0, 
                   'Cost Optimization': 1.0, 'Operational Excellence': 0.9, 'Sustainability': 0.8}
        
        weighted = sum(ps.score * weights.get(p, 1.0) for p, ps in pillar_scores.items())
        total = sum(weights.get(p, 1.0) for p in pillar_scores)
        return int(weighted / total) if total > 0 else 0
    
    def _determine_risk(self, score: int) -> str:
        """Determine risk level"""
        if score >= 80: return "Low"
        if score >= 60: return "Medium"
        if score >= 40: return "High"
        return "Critical"
    
    def _calculate_aiml_health_score(self) -> int:
        """Calculate AI/ML health score based on detected services and findings"""
        if not self.inventory.has_ai_ml_workloads:
            return 0  # No AI/ML workloads detected
        
        # Start with base score of 100
        score = 100
        
        # Count AI/ML specific findings
        aiml_services = ['SageMaker', 'Bedrock', 'Rekognition', 'Comprehend', 'Lex', 'Kendra', 'Personalize']
        aiml_findings = [f for f in self.findings if f.source_service in aiml_services]
        
        for finding in aiml_findings:
            if finding.severity == 'CRITICAL':
                score -= 20
            elif finding.severity == 'HIGH':
                score -= 10
            elif finding.severity == 'MEDIUM':
                score -= 5
            elif finding.severity == 'LOW':
                score -= 2
        
        # Bonus points for good practices
        if self.inventory.bedrock_guardrails > 0 and self.inventory.bedrock_agents > 0:
            score += 5  # Has guardrails for agents
        
        if self.inventory.sagemaker_pipelines > 0:
            score += 5  # Has MLOps pipelines
        
        return max(0, min(100, score))

# ============================================================================
# RENDER FUNCTION
# ============================================================================

def render_landscape_scanner_tab():
    """Render the landscape scanner tab"""
    is_demo = st.session_state.get('app_mode', 'demo') == 'demo'
    
    if is_demo:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #1565C0 0%, #1976D2 100%); padding: 2rem; border-radius: 12px; margin-bottom: 1.5rem;">
            <h2 style="color: white; margin: 0;"> Demo Mode - AWS Landscape Scanner</h2>
            <p style="color: #BBDEFB; margin: 0.5rem 0 0 0;">Experience the scanner with comprehensive sample data</p>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #1a472a 0%, #2d5a3d 100%); padding: 2rem; border-radius: 12px; margin-bottom: 1.5rem;">
            <h2 style="color: #98FB98; margin: 0;"> Live Mode - AWS Landscape Scanner</h2>
            <p style="color: #90EE90; margin: 0.5rem 0 0 0;">Scanning your real AWS resources</p>
        </div>
        """, unsafe_allow_html=True)
        
        if not st.session_state.get('aws_connected'):
            st.warning(" Connect to AWS in the AWS Connector tab first, or switch to Demo mode")
            return
    
    # Options
    col1, col2 = st.columns(2)
    with col1:
        regions = st.multiselect(
            "Regions",
            ["us-east-1", "us-west-2", "eu-west-1", "ap-southeast-1"],
            default=["us-east-1", "us-west-2"]
        )
    with col2:
        generate_pdf = st.checkbox(" Generate PDF Report", value=True)
    
    # Run scan button
    btn_text = " Run Demo Assessment" if is_demo else " Run Live Assessment"
    
    if st.button(btn_text, type="primary", use_container_width=True):
        progress = st.progress(0)
        status = st.empty()
        
        if is_demo:
            import time
            steps = [
                (0.1, "Initializing..."), (0.2, "Scanning IAM..."),
                (0.3, "Scanning S3..."), (0.4, "Scanning EC2..."),
                (0.5, "Scanning RDS..."), (0.6, "Scanning VPC..."),
                (0.7, "Analyzing Security Hub..."), (0.8, "Checking compliance..."),
                (0.9, "Calculating scores..."), (1.0, "Complete!")
            ]
            for p, m in steps:
                progress.progress(p)
                status.text(m)
                time.sleep(0.3)
            
            assessment = generate_demo_assessment()
        else:
            # Get session and validate it exists
            session = st.session_state.get('aws_session')
            
            if not session:
                st.error(" AWS session not found. Please connect to AWS in the AWS Connector tab first.")
                return
            
            # Create scanner with validated session
            try:
                scanner = AWSLandscapeScanner(session)
                assessment = scanner.run_scan(regions, lambda p, m: (progress.progress(p), status.text(m)))
            except Exception as e:
                st.error(f" Scan failed: {str(e)}")
                st.info(" Try reconnecting in the AWS Connector tab or switch to Demo mode")
                return
        
        st.session_state.landscape_assessment = assessment
        
        # Display results
        render_assessment_summary(assessment)
        render_pillar_scores(assessment)
        render_findings_list(assessment)
        
        if generate_pdf:
            render_pdf_download(assessment)

def render_assessment_summary(assessment: LandscapeAssessment):
    """Render assessment summary"""
    st.markdown("---")
    st.markdown("###  Assessment Summary")
    
    # Check if AI/ML workloads detected
    has_aiml = assessment.inventory.has_ai_ml_workloads if hasattr(assessment.inventory, 'has_ai_ml_workloads') else False
    
    if has_aiml:
        col1, col2, col3, col4, col5, col6 = st.columns(6)
    else:
        col1, col2, col3, col4, col5 = st.columns(5)
        col6 = None
    
    score_color = "#388E3C" if assessment.overall_score >= 80 else "#FBC02D" if assessment.overall_score >= 60 else "#D32F2F"
    
    with col1:
        st.markdown(f"""
        <div style="text-align: center; padding: 1rem; background: white; border-radius: 10px;">
            <div style="font-size: 2.5rem; font-weight: bold; color: {score_color};">{assessment.overall_score}</div>
            <div style="color: #666;">WAF Score</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        risk_icon = {"Low": "", "Medium": "", "High": "", "Critical": ""}.get(assessment.overall_risk, "")
        st.metric("Risk Level", f"{risk_icon} {assessment.overall_risk}")
    
    with col3:
        st.metric("Total Findings", len(assessment.findings))
    
    with col4:
        critical = sum(1 for f in assessment.findings if f.severity == 'CRITICAL')
        high = sum(1 for f in assessment.findings if f.severity == 'HIGH')
        st.metric("Critical/High", f"{critical}/{high}")
    
    with col5:
        st.metric("Potential Savings", f"${assessment.savings_opportunities:,.0f}/mo")
    
    # AI/ML Health Indicator (NEW)
    if has_aiml and col6:
        with col6:
            aiml_score = assessment.aiml_health_score if hasattr(assessment, 'aiml_health_score') else 0
            aiml_color = "#388E3C" if aiml_score >= 80 else "#FBC02D" if aiml_score >= 60 else "#D32F2F"
            services_count = len(assessment.inventory.ai_ml_services_detected) if hasattr(assessment.inventory, 'ai_ml_services_detected') else 0
            st.markdown(f"""
            <div style="text-align: center; padding: 1rem; background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; border: 2px solid {aiml_color};">
                <div style="font-size: 2rem; font-weight: bold; color: {aiml_color};">{aiml_score}</div>
                <div style="color: #ccc; font-size: 0.8rem;"> AI/ML Health</div>
                <div style="color: #888; font-size: 0.7rem;">{services_count} services</div>
            </div>
            """, unsafe_allow_html=True)
    
    # AI/ML Detection Banner (NEW)
    if has_aiml:
        services_list = assessment.inventory.ai_ml_services_detected if hasattr(assessment.inventory, 'ai_ml_services_detected') else []
        aiml_findings_count = len(assessment.aiml_findings) if hasattr(assessment, 'aiml_findings') else 0
        
        st.markdown(f"""
        <div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); 
                    border-radius: 10px; padding: 15px; margin: 15px 0;
                    border-left: 4px solid #9b59b6;">
            <h4 style="margin: 0; color: white;"> AI/ML Workloads Detected</h4>
            <p style="margin: 5px 0; color: #ccc;">
                <strong>Services:</strong> {', '.join(services_list[:6])}
                {f' +{len(services_list) - 6} more' if len(services_list) > 6 else ''}
            </p>
            <p style="margin: 0; font-size: 0.9em; color: #888;">
                {aiml_findings_count} AI/ML-specific findings | 
                Visit the <strong> AI Lens</strong> tab for detailed ML, GenAI, and Responsible AI assessment
            </p>
        </div>
        """, unsafe_allow_html=True)

def render_pillar_scores(assessment: LandscapeAssessment):
    """Render pillar scores"""
    st.markdown("###  Pillar Scores")
    
    cols = st.columns(6)
    icons = {
        "Security": "", "Reliability": "", "Performance Efficiency": "",
        "Cost Optimization": "", "Operational Excellence": "", "Sustainability": ""
    }
    
    for idx, (pillar, ps) in enumerate(assessment.pillar_scores.items()):
        with cols[idx]:
            color = "#388E3C" if ps.score >= 80 else "#FBC02D" if ps.score >= 60 else "#D32F2F"
            st.markdown(f"""
            <div style="text-align: center; padding: 0.5rem; background: white; border-radius: 8px;">
                <div style="font-size: 1.5rem;">{icons.get(pillar, '')}</div>
                <div style="font-size: 1.5rem; font-weight: bold; color: {color};">{ps.score}</div>
                <div style="font-size: 0.7rem; color: #666;">{pillar.split()[0]}</div>
                <div style="font-size: 0.6rem; color: #999;">{ps.findings_count} findings</div>
            </div>
            """, unsafe_allow_html=True)

def render_findings_list(assessment: LandscapeAssessment):
    """Render detailed findings list"""
    st.markdown("###  Detailed Findings")
    
    # Group by severity
    for severity in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
        sev_findings = [f for f in assessment.findings if f.severity == severity]
        if not sev_findings:
            continue
        
        icon = {'CRITICAL': '', 'HIGH': '', 'MEDIUM': '', 'LOW': ''}.get(severity, '')
        st.markdown(f"#### {icon} {severity} ({len(sev_findings)})")
        
        for finding in sev_findings:
            with st.expander(f"{finding.title}"):
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    st.markdown(f"**Pillar:** {finding.pillar}")
                    st.markdown(f"**Service:** {finding.source_service}")
                    st.markdown(f"**Description:** {finding.description}")
                    
                    if finding.affected_resources:
                        st.markdown(f"**Affected Resources:** {', '.join(finding.affected_resources[:5])}")
                
                with col2:
                    st.markdown(f"**Effort:** {finding.effort}")
                    if finding.estimated_savings > 0:
                        st.markdown(f"**Savings:** ${finding.estimated_savings:,.0f}/mo")
                    if finding.compliance_frameworks:
                        st.markdown(f"**Compliance:** {', '.join(finding.compliance_frameworks[:3])}")
                
                if finding.recommendation:
                    st.success(f" **Recommendation:** {finding.recommendation}")
                
                if finding.remediation_steps:
                    with st.expander(" Remediation Steps"):
                        for i, step in enumerate(finding.remediation_steps, 1):
                            st.markdown(f"{i}. {step}")

def render_pdf_download(assessment: LandscapeAssessment):
    """Render PDF download button"""
    st.markdown("---")
    
    try:
        from pdf_report_generator import generate_comprehensive_waf_report
        
        pdf_bytes = generate_comprehensive_waf_report(assessment)
        
        st.download_button(
            " Download Comprehensive PDF Report",
            pdf_bytes,
            file_name=f"AWS_WAF_Report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
            mime="application/pdf"
        )
    except Exception as e:
        st.warning(f"PDF generation unavailable: {e}")